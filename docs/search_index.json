[["introduction.html", "Estimating Social Animal Models in Stan Introduction", " Estimating Social Animal Models in Stan Jordan S. Martin &amp; Adrian V. Jaeggi 2021-07-07 Introduction body { text-align: justify} This guidebook provides a comprehensive overview of how to estimate social animal models (SAMs) with the Stan statistical programming language (Carpenter et al. 2017) in R (R Core Team 2020). A detailed theoretical treatment of SAMs and their empirical motivation can be found in the forthcoming paper (Martin and Jaeggi 2021) Social animal models for quantifying plasticity, assortment, and selection on interacting phenotypes. This guide focuses on various issues related to coding SAMs in Stan for varying study designs and more complex trait interactions. The overarching goal of the guidebook is to aid researchers in flexibly and appropriately applying SAMs to their own empirical datasets. Therefore, in addition to basic coding tutorials, we also intend to add worked examples relevant to specific challenges such as modeling spatial autocorrelation or hierarchical phenotypes. Please contact Jordan Scott Martin if you have any questions, as well as if youd like to suggest a worked example of interest to your own research. The guidebook is a work in progress and will be updated over time. Resources "],["using-stan-in-r.html", "1 Using Stan in R 1.1 Why Stan? 1.2 Getting Started 1.3 Bayesian inference 1.4 Basic coding tutorial 1.5 Animal models", " 1 Using Stan in R body { text-align: justify} 1.1 Why Stan? SAMs cannot be straightforwardly implemented with currently available software for quantitative genetic analysis, such as the frequentist ASREML program (Butler et al. 2018) or the Bayesian open-source R package MCMCglmm (Hadfield 2010). The classical animal models estimated by these programs can be used to describe reaction norms defined over non-social environments, with reaction norm slopes estimated on directly measured environmental gradients. However, social environments defined by partner phenotypes present novel challenges for animal models, such as accounting for temporal feedback between social partners phenotypes, differentiating the effects of assortment and social plasticity between partners, and avoiding bias due to correlated residual effects on measurements taken within and among social interactions (Martin and Jaeggi 2021). SAMs address these challenges by estimating plasticity, assortment, and selection directly on the latent social reaction norms (SRNs) governing repeatable individual variation. A highly flexible modeling framework is required to estimate these latent (i.e. indirectly measured) interactions with raw empirical data, as well as to use them for predicting social evolutionary change. Stan (Carpenter et al. 2017) is an open-source programming language for estimating probabilistic models of arbitrary complexity, which can interface with multiple statistical environments such as R (R Core Team 2020). Stan also facilitates fully Bayesian inference using state-of-the-art Markov Chain Monte Carlo (MCMC) sampling techniques. In particular, the No U-Turn Sampler (NUTS) implimented in Stan has been found to perform particularly well for quantitative genetic analysis (Nishio and Arakawa 2019). Stan is thus an ideal platform for flexibly estimating SAMs in any empirical system, as is further discussed in the main text (Martin and Jaeggi 2021). Using Bayesian posteriors rather than point estimates will also promote more robust biological inferences with SAMs, as statistical uncertainty can be easily carried forward across multiple stages of analysis (Stinchcombe, Simonsen, and Blows 2014). This provides a crucial means of quantifying uncertainty in the predicted direction and magnitude of social evolution. 1.2 Getting Started Stan interfaces with R through the RStan package (Carpenter et al. 2017), providing an efficient means of integrating SAMs into pre-existing data analysis pipelines. However, you will first need to install Stan on your computer and ensure that it is appropriately configured with your C++ toolchain. This can be accomplished by following the instructions for your operating system on the RStan Getting Started page. Once you are able to effectively use RStan, you can begin creating the .stan files necessary for estimating SAMs. These files can be composed using RStudio or any text editor, as well as directly in R with write() write(&quot;// for Stan comments functions{...} // Stan models are composed of data {...} // multiple programming blocks transformed data {...} //only data, parameters, and model parameters {...} //blocks are necessary transformed parameters {...} model {...} generated quantities {...} &quot;, &quot;mod1.stan&quot;) Once an appropriate .stan file is prepared, it can be compiled in R for the C++ toolchain using the stan_model() function and subsequently estimated with an appropriate list of empirical data using the sampling() function. The resulting posteriors of a model can then be accessed with the extract() function and manipulated for any further quantities or analyses of interest. #load package library(rstan) #compiles the model in C++ for MCMC estimation mod1 = stan_model(&quot;mod1.stan&quot;) #samples posterior distribution of the model with default MCMC settings results = sampling(object = mod1, data = data) #extracts posterior estimates samples = extract(results) 1.3 Bayesian inference A detailed overview of the benefits of Bayesian inference is beyond the scope of this guidebook, as attention is placed on coding and computational concerns rather than interpretation. We encourage researchers unfamiliar with fully Bayesian inference to see McElreath (2020) for further discussion. Lemoine (2019) also demonstrates why weakly regularizing (or weakly informative) priors are often preferable to the flat or diffuse priors more commonly used in evolutionary ecology. In general, we encourage researchers to utilize the benefits of fully Bayesian inference while working in Stan, rather than attempting to mimic classical inference and null-hypothesis testing approaches. Gelman et al. (2020) provide a very useful general discussion of Bayesian workflow from initial estimation to model comparison and selection. A basic understanding of MCMC and prior and posterior distributions is necessary to fully understand model estimation in Stan. MCMC provides a means of approximating any continous probability distribution, with a finite set of samples taken in proportion to the underlying target probability density. As a consequence, Stan models return objects with many MCMC samples for each model parameter, rather than single point estimates. These samples can then be summarized to approximate the shape of the truly continous target posterior distribution, as is shown throughout the coding tutorials. 1.4 Basic coding tutorial Stan uses its own language for writing probabilistic models, including a variety of built-in functions designed to aid in efficient computation. The biggest conceptual hurdle for new users of Stan is likely to be the absence of an intuitive R-like syntax for specifying model formulas, such as formulas like y ~ x + (1|z) that can be used to quickly specify complex generalized linear mixed-effects models. These formulas facilitate highly efficient statistical modeling, but do so at the cost of limiting users ability to specify atypical model structures. Instead, Stan provides the benefit of nearly unlimited flexibility in model specification, with the added cost of a steeper learning curve. In particular, models must be formally specified with mathematically appropriate likelihood functions, rather than this process being handled on the back-end through textual inputs from the user such as family= poisson(link = \"log\"). This may at first seem like a cumbersome task, but it provides a degree of independence and creativity for data analysis that is otherwise unavailable. It is this autonomy that makes it possible to unbiasedly estimate SAMs in Stan, which to the best of our knowledge cannot be accomplished with any other mainstream statistical software. Nonetheless, it is important to recognize that some practice and trial-and-error will be required to gain competency and comfortability with Stan. We therefore encourage those interested in SAMs to review the Stan Reference Manual, as well the extensive collection of Stan Case Studies, which will provide a more robust foundation for estimating any model of interest in Stan. Here we review some basics of Stan that will be necessary for following the coding tutorials in the rest of the guidebook. To make this introduction more concrete, we simulate a simple data structure appropriately described by a Gaussian random regression model, with 50 subjects and 2 repeated measures per subject across an environmental gradient \\(x\\). Formally, the model for observation i of individual j is given by \\[z_{ij}=\\mu_0+\\mu_{j}+\\left( \\beta_0 + \\beta_{j} \\right) x_{ij}+\\epsilon_i\\] \\[ \\begin{bmatrix} \\boldsymbol{\\mu} \\\\ \\boldsymbol{\\beta_{\\mathrm{ }}} \\end{bmatrix} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{P}} ) : \\boldsymbol{\\mathrm{ }} = \\begin{bmatrix} \\mathrm{Var}( {\\mu} ) &amp; \\mathrm{Cov}( {\\mu}, \\boldsymbol{\\beta_{\\mathrm{ }}}) \\\\ \\mathrm{Cov}(\\boldsymbol{\\beta_{\\mathrm{ }}}, {\\mu} ) &amp; \\mathrm{Var}( \\boldsymbol{\\beta_{\\mathrm{ }}} ) \\end{bmatrix} \\] \\[ \\boldsymbol{\\epsilon} \\sim \\mathrm{Normal}(0, \\boldsymbol{\\Sigma} ): \\boldsymbol{\\Sigma} = [\\mathrm{Var}(\\boldsymbol{\\epsilon})]\\] where \\(\\mu_0\\) and \\(\\beta_1\\) are fixed population-level intercepts and slopes respectively, with the vectors \\(\\boldsymbol{\\mu_{\\mathrm{ }}}\\) and \\(\\boldsymbol{\\beta_{\\mathrm{ }}}\\) containing individual-specific phenotypic deviations from the population values (i.e. random intercepts and slopes). The probability density function of this Gaussian variable can be equivalently written as \\[z_{ij} \\sim \\mathrm{Normal}(\\mu_0 + \\mu_{j}+ \\left( \\beta_1 + \\beta_{j} \\right) x_{ij}, \\boldsymbol{\\Sigma})\\] It is often easier to specify model likelihoods and priors over standard deviations and correlation matrices in Stan, rather than the variances and covariances represented in the formal model. These parameters can always be derived from one another with simple transformations. For variances and standard deviations \\[\\mathrm{SD}( \\boldsymbol{\\mu_{\\mathrm{ }}} ) = \\mathrm{Sqrt(Var} (\\boldsymbol{\\boldsymbol{\\mu_{\\mathrm{ }}} }) ) , \\quad \\mathrm{SD}( \\boldsymbol{\\beta_{\\mathrm{ }}} ) = \\mathrm{Sqrt(Var} (\\boldsymbol{\\boldsymbol{\\beta_{\\mathrm{ }}} }) )\\] Similarly, the covariance matrix \\(\\boldsymbol{\\mathrm{P_{cov}}}\\) can be derived by pre- and post-multiplying the correlation matrix \\(\\boldsymbol{\\mathrm{P_{cor}}}\\) with diagonal matrices \\(\\boldsymbol{\\mathrm{P_{sd}}}\\) of these standard deviations \\[\\boldsymbol{\\mathrm{P_{cov}}} = \\boldsymbol{\\mathrm{P_{sd}}} \\boldsymbol{\\mathrm{P_{cor}}}\\boldsymbol{\\mathrm{P_{sd}}}\\] \\[\\boldsymbol{\\mathrm{P_{sd}}}= \\begin{bmatrix} \\mathrm{SD}( \\boldsymbol{\\mu_{\\mathrm{ }}} ) &amp; 0 \\\\ 0 &amp; \\mathrm{SD}( \\boldsymbol{\\beta_{\\mathrm{ }}} ) \\end{bmatrix}, \\quad \\boldsymbol{\\mathrm{P_{cor}}} = \\begin{bmatrix} 1 &amp; \\mathrm{Cor}( \\boldsymbol{\\mu_{\\mathrm{ }}}, \\boldsymbol{\\beta_{\\mathrm{ }}} ) \\\\ \\mathrm{Cor}( \\boldsymbol{\\beta_{\\mathrm{ }}} , \\boldsymbol{\\mu_{\\mathrm{ }}} ) &amp; 1 \\end{bmatrix} \\] We can simulate a random dataset from this model in R, along with an index variable id that tracks which individual (I = 1 - 50) is being measured at each observation (N = 1-100). library(mvtnorm) N = 100 #total observations I = 50 #total individuals intercept = 1 #global intercept beta1 = 0.3 #fixed effect regression coefficient SD_intercept = 0.3 #standard deviation of random intercepts SD_slope = 0.3 SD_residual = 1 cor_RE = 0.3 #correlation of random intercepts and slopes #individual-level index id = rep(seq(1, I), each = N/I) #i.e. two observations per individual #simulate fixed effect covariate x = rnorm(100,0,1) #simulate random individual deviations Pcor = matrix( c(1, cor_RE, cor_RE, 1), nrow = 2, ncol = 2 ) Psd = matrix( c(SD_intercept, 0, 0, SD_slope), nrow = 2, ncol = 2 ) Pcov = Psd %*% Pcor %*% Psd re_P = rmvnorm(I, mean = c(0,0), sigma = Pcov) #rows = I, cols = intercepts and slopes #individual-level parameters mu = re_P[,1] beta = re_P[,2] #residual effects epsilon = rnorm(100, 0, SD_residual ) #measured response (100 response values for 50 subjects) z = intercept + mu[id] + (beta1 + beta[id])*x + epsilon #combine into list for Stan #other values are empirically unobserved and will be model parameters stan_data = list(z = z, x = x, id = id, N = N, I = I) We can now program a Stan model to infer the data-generating process with these empirical observations. For any .stan file composed with a text editor, the following programming blocks will be recognized and all model code inside each block will be processed sequentially. functions { } data { } transformed data { } parameters { } transformed parameters { } model { } generated quantities { } The data, parameters, and model blocks are specified for any model, while the other blocks provide optional declarations and statements. In most statistical software, empirical data are input with a single matrix or dataframe. Rather than inputting a single dataframe or matix to RStan, a list can be provided with data for each scalar (real or integer), vector, or matrix declared in the .stan file. The names of these data objects are declared along with their expected dimensions, which ensures that inappropriate data structures or likelihood functions will throw errors. For the simulated data, we first declare all the measured variables and indices relevant to model estimation. We use // rather than # for comments in Stan. data { int&lt;lower=1&gt; N; //length of response vector/total observations int&lt;lower=1&gt; I; //number of individuals int&lt;lower=1&gt; id[N]; //N integer indices matching observations of z to the individual identity vector[N] x; //vector of covariate values for fixed effect vector[N] z; //vector of response values } This declarative approach requires that particular attention is given to the order of data input to the model, as values will need to be appropriately aligned and indexed throughout the model specification. However, it also provides additional benefits such as facilitating multi-response models with heterogeneous dimensions, as well as allowing for arbitrarily complex forms of social interaction to be specified in the model likelihood using appropriate indices of the relevant vectors or matrices. We specify model parameters in accordance with the formal model used for the simulation, with standard deviations and correlation matrices replacing variances and covariance matrices. For simplicity, we use _P to indicate phenotypic (co)variances and values in the Stan code, with _R used to indicate residual (co)variance terms. parameters { //fixed effects real mu_0; //global intercept real beta_1; //fixed effect coefficient for covariate x //random effects corr_matrix[2] Pcor; //correlation matrix of random effects vector&lt;lower=0&gt;[2] sd_P; //standard deviations of random effects real&lt;lower=0&gt; sd_R; //standard deviation of residuals matrix[I,2] re_P; //individual-level phenotypic deviations (random intercepts and slopes) } Note that rather than declaring the random effects as separate vectors, we instead declare a matrix for both individual intercept and slope values, which we use in the model block for declaring the covariance between these parameters. It is necessary to specify &lt;lower=0&gt; so that the standard deviation parameters are lower bound at zero. The other parameters in the formal model are simply combinations of these fundamental parameters. The transformed parameters block of a .stan file is intended for such purposes. In particular, the covariance matrix \\(\\boldsymbol{\\mathrm{P_{cov}}}\\) can be derived with the standard deviations sd_P and the correlation matrix Pcor as shown above. Separating these parameters is useful for increasing model clarity, as well for enhancing the efficiency of MCMC sampling as demonstrated further below. transformed parameters { cov_matrix[2] Pcov = diag_matrix(sd_P) * Pcor * diag_matrix(sd_P); //cov of random effects } This new transformed parameter P can now be used in the model block to more clearly express the likelihood function. Note that new objects can also be declared inside the model block prior to specifying the likelihood. However, any objects created in the model block are temporary and will not be saved along with the MCMC samples of objects declared in the parameters and transformed parametrs blocks. This can be useful for creating pragmatic objects that enable more efficient coding but do not need to be directly interpreted. For instance, rather than subsetting the matrix of individual random effects re_P inside the model likelihood, we can instead create two temporary vectors mu and beta to more intuitively write the likelihood function. Following the formal model above, we specify the response \\(z_{ij}\\) as a function of the linear predictor containing population parameters as well as individual intercepts \\(\\mu_j\\) and slopes in response to the environmental covariate \\(\\beta_j\\), as well as stochastic effects with standard deviation \\(\\mathrm{SD(\\boldsymbol{\\epsilon})}=\\)sd_R. The random effects are sampled from a zero-centered multivariate normal with covariance matrix \\(\\boldsymbol{\\mathrm{P_{cov}}}\\). model { vector[I] mu = col(re_P, 1); //temporary individual-level intercepts vector[I] beta = col(re_P, 2); //temporary individual-level slopes //model likelihood //use index id to match response vector length z ~ normal(mu_0 + mu[id] + (beta_1 + beta[id]).*x, sd_R); for(i in 1:I) //each individual&#39;s random effects ~ MVN(0,P_cov) re_P[i] ~ multi_normal([0,0], Pcov); //priors //fixed effects mu_0 ~ normal(0,1); beta_1 ~ normal(0,1); //random effects Pcor ~ lkj_corr(2); to_vector(sd_P) ~ cauchy(0,1); sd_R ~ cauchy(0,1); } Model priors are set for all parameters declared in the original programming block, while transformed parameters do not receive priors. We use general purpose, weakly regularizing priors to reduce the risk of inferential bias and enhance model identification, which will be crucial for SAMs relying on interactions among many latent variables. Interested readers should see Lemoine (2019) and McElreath (2020) for further discussion on the choice of model priors, as well as the clear limitations of using highly diffuse, flat, and/or improper priors that are more commonly utilized. Finally, rather than post-processing the posterior SDs ourselves to derive variances, we can instead use the generated quantities block to calculate the variances during model estimation. generated quantities { vector[2] V_P = sd_P .* sd_P; //RN intercept [1] and slope [2] variance real V_R = sd_R * sd_R; //residual variance (=Sigma matrix) } The posterior object returned from this model will now contain the random effects variances and covariance matrix, along with the SDs and correlation matrix. Each of the blocks can now be saved together in a single .stan file, which can be accomplished with a text editor or inside R. write(&quot; data { int&lt;lower=1&gt; N; //length of response vector/total observations int&lt;lower=1&gt; I; //number of individuals int&lt;lower=1&gt; id[N]; //N integer indices matching observations of z to the individual identity vector[N] x; //vector of covariate values for fixed effect vector[N] z; //vector of response values } parameters { //fixed effects real mu_0; //global intercept real beta_1; //fixed effect coefficient for covariate x //random effects corr_matrix[2] Pcor; //correlation matrix of random effects vector&lt;lower=0&gt;[2] sd_P; //standard deviations of random effects real&lt;lower=0&gt; sd_R; //standard deviation of residuals matrix[I,2] re_P; //individual-level phenotypic deviations (random intercepts and slopes) } transformed parameters { cov_matrix[2] Pcov = diag_matrix(sd_P) * Pcor * diag_matrix(sd_P); //cov of random effects } model { vector[I] mu = col(re_P, 1); //temporary individual-level intercepts vector[I] beta = col(re_P, 2); //temporary individual-level slopes //model likelihood //use index id to match response vector length z ~ normal(mu_0 + mu[id] + (beta_1 + beta[id]).*x, sd_R); for(i in 1:I) //each individual&#39;s random effects ~ MVN(0,P_cov) re_P[i] ~ multi_normal([0,0], Pcov); //priors //fixed effects mu_0 ~ normal(0,1); beta_1 ~ normal(0,1); //random effects Pcor ~ lkj_corr(2); to_vector(sd_P) ~ cauchy(0,1); sd_R ~ cauchy(0,1); } generated quantities { vector[2] V_P = sd_P .* sd_P; //RN intercept [1] and slope [2] variance real V_R = sd_R * sd_R; //residual variance (=Sigma matrix) }&quot;, &quot;mod1.stan&quot;) The model is now ready for estimation. We manually specify that the MCMC sampler should use 1500 iterations per chain to converge on the target joint posterior distribution warmup=1500, with the subsequent 1000 iterations used as posterior samples iter = 2500 (i.e. iter - warmup = number of MCMC samples per chain). init = 0 initializes the samplers near null values. Four MCMC chains are used to assess model convergence across independent random samplers chains=4, with one core assigned to each chain for parallel processing cores=4. The adapt_delta=0.90 argument reduces the risk of divergent transitions during sampling. library(rstan) ## Loading required package: StanHeaders ## Loading required package: ggplot2 ## rstan (Version 2.21.2, GitRev: 2e1f913d3ca3) ## For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()). ## To avoid recompilation of unchanged Stan programs, we recommend calling ## rstan_options(auto_write = TRUE) ## Do not specify &#39;-march=native&#39; in &#39;LOCAL_CPPFLAGS&#39; or a Makevars file mod1 = stan_model(&quot;mod1.stan&quot;) ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): &#39;C:/rtools40/usr/mingw_/bin/g++&#39; not found stan_results &lt;- sampling(mod1, data=stan_data, init = 0, warmup=1500, iter = 2500, chains=4, cores=4, control=list(adapt_delta=0.90) ) ## Warning: There were 11 divergent transitions after warmup. See ## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup ## to find out why this is a problem and how to eliminate them. ## Warning: There were 4 chains where the estimated Bayesian Fraction of Missing Information was low. See ## http://mc-stan.org/misc/warnings.html#bfmi-low ## Warning: Examine the pairs() plot to diagnose sampling problems ## Warning: The largest R-hat is NA, indicating chains have not mixed. ## Running the chains for more iterations may help. See ## http://mc-stan.org/misc/warnings.html#r-hat ## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. ## Running the chains for more iterations may help. See ## http://mc-stan.org/misc/warnings.html#bulk-ess ## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. ## Running the chains for more iterations may help. See ## http://mc-stan.org/misc/warnings.html#tail-ess Stan flags a few potential issues with the MCMC sampler. Note that the warning ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): 'C:/rtools40/usr/mingw_/bin/g++' not found during compilation of the model will sometimes appear on Windows computers and can be safely ignored. Further description of the sampler warnings can be found in the Stan Warning Guide. One warning is that The largest R-hat is NA, indicating chains have not mixed. Stan does not know whether some parameter values are fixed (causing Rhat = NA) because the sampler is stuck, or because the model has been intentionally specified with fixed parameter values (e.g. diagonals fixed to 1 in a correlation matrix or an intercept forced to 0). For the specified model, this is a harmless warning that can be safely ignored. However, we can also check for issues by looking at the Rhat values of all model parameters using summary() on the saved results. If an expected parameter is missing from the table or shows NA, this likely indicates an unintentional error in the model code. summary(stan_results)$summary[,&quot;Rhat&quot;] ## mu_0 beta_1 Pcor[1,1] Pcor[1,2] Pcor[2,1] Pcor[2,2] sd_P[1] sd_P[2] sd_R re_P[1,1] re_P[1,2] re_P[2,1] re_P[2,2] re_P[3,1] ## 1.0005876 1.0018848 NaN 1.0048164 1.0048164 0.9989995 1.0508801 1.0411834 1.0106009 1.0080508 1.0004907 1.0027878 0.9995325 1.0072528 ## re_P[3,2] re_P[4,1] re_P[4,2] re_P[5,1] re_P[5,2] re_P[6,1] re_P[6,2] re_P[7,1] re_P[7,2] re_P[8,1] re_P[8,2] re_P[9,1] re_P[9,2] re_P[10,1] ## 1.0059441 1.0005787 1.0061680 1.0067278 1.0008115 1.0022377 1.0007367 1.0002988 1.0010779 1.0123918 1.0004806 1.0070715 0.9997806 1.0078175 ## re_P[10,2] re_P[11,1] re_P[11,2] re_P[12,1] re_P[12,2] re_P[13,1] re_P[13,2] re_P[14,1] re_P[14,2] re_P[15,1] re_P[15,2] re_P[16,1] re_P[16,2] re_P[17,1] ## 1.0114427 1.0008475 1.0040321 1.0012149 1.0047620 1.0036244 0.9998361 1.0102958 1.0028727 1.0037435 0.9994277 1.0007278 1.0009889 1.0013277 ## re_P[17,2] re_P[18,1] re_P[18,2] re_P[19,1] re_P[19,2] re_P[20,1] re_P[20,2] re_P[21,1] re_P[21,2] re_P[22,1] re_P[22,2] re_P[23,1] re_P[23,2] re_P[24,1] ## 1.0091566 1.0055960 1.0021099 1.0066138 1.0022808 1.0043456 1.0014794 1.0005657 0.9998253 1.0012615 1.0030955 0.9995379 1.0005400 0.9998803 ## re_P[24,2] re_P[25,1] re_P[25,2] re_P[26,1] re_P[26,2] re_P[27,1] re_P[27,2] re_P[28,1] re_P[28,2] re_P[29,1] re_P[29,2] re_P[30,1] re_P[30,2] re_P[31,1] ## 0.9999637 1.0117507 1.0052045 0.9992939 1.0085934 1.0013197 0.9996673 1.0015989 1.0009549 0.9998335 0.9998735 1.0015152 1.0065507 1.0043107 ## re_P[31,2] re_P[32,1] re_P[32,2] re_P[33,1] re_P[33,2] re_P[34,1] re_P[34,2] re_P[35,1] re_P[35,2] re_P[36,1] re_P[36,2] re_P[37,1] re_P[37,2] re_P[38,1] ## 1.0002429 1.0169099 1.0018349 1.0158547 1.0031068 0.9998833 1.0024071 1.0061996 1.0114036 1.0046015 0.9997174 1.0017230 1.0074334 1.0033723 ## re_P[38,2] re_P[39,1] re_P[39,2] re_P[40,1] re_P[40,2] re_P[41,1] re_P[41,2] re_P[42,1] re_P[42,2] re_P[43,1] re_P[43,2] re_P[44,1] re_P[44,2] re_P[45,1] ## 1.0127164 1.0013276 0.9993975 0.9993723 0.9999868 1.0013075 0.9998237 1.0001282 1.0014441 1.0197587 1.0007479 1.0019460 1.0009725 0.9996981 ## re_P[45,2] re_P[46,1] re_P[46,2] re_P[47,1] re_P[47,2] re_P[48,1] re_P[48,2] re_P[49,1] re_P[49,2] re_P[50,1] re_P[50,2] Pcov[1,1] Pcov[1,2] Pcov[2,1] ## 0.9998352 0.9993495 0.9997898 1.0009072 0.9998898 1.0041737 1.0005373 1.0067217 0.9996497 1.0158034 0.9994923 1.0411227 1.0060642 1.0060642 ## Pcov[2,2] V_P[1] V_P[2] V_R lp__ ## 1.0309514 1.0411227 1.0309514 1.0101213 1.0455487 In addition to the Rhat warning, the effective sample sizes of some model parameters are too low to ensure accurate inferences. It is helpful to see which parameters are causing these warnings by sorting on the lowest n_eff values in the summary table. sort(summary(stan_results)$summary[,&quot;n_eff&quot;]) ## sd_P[1] lp__ Pcov[1,1] V_P[1] sd_P[2] re_P[43,1] re_P[32,1] V_P[2] Pcov[2,2] re_P[33,1] re_P[50,1] re_P[8,1] re_P[1,1] re_P[10,2] ## 51.35573 52.75710 71.42438 71.42438 130.27812 149.77592 165.56449 167.23984 167.23984 181.30801 232.52177 310.02847 310.91440 355.29375 ## re_P[14,1] re_P[38,2] re_P[35,2] re_P[25,1] re_P[17,2] sd_R V_R re_P[5,1] re_P[37,2] re_P[49,1] re_P[26,2] re_P[10,1] re_P[35,1] re_P[3,1] ## 375.69415 383.96765 410.06034 421.95729 475.20697 478.75057 531.25935 535.00976 535.37072 542.78545 542.80714 566.69931 588.12174 609.95590 ## Pcor[1,2] Pcor[2,1] Pcov[1,2] Pcov[2,1] re_P[19,1] re_P[31,1] re_P[4,2] re_P[9,1] re_P[30,2] re_P[20,2] re_P[25,2] re_P[36,1] re_P[43,2] re_P[2,1] ## 626.67765 626.67765 697.28592 697.28592 732.02134 740.03524 744.82404 820.56372 876.87182 888.06217 898.02117 1034.07741 1050.05501 1074.21365 ## re_P[18,1] re_P[12,2] re_P[34,2] re_P[13,1] re_P[20,1] re_P[3,2] re_P[37,1] re_P[39,1] re_P[5,2] re_P[32,2] re_P[22,2] re_P[6,1] re_P[18,2] re_P[14,2] ## 1074.32823 1100.97813 1332.71082 1397.65260 1588.93732 1607.14196 1640.90421 1687.18930 1835.44984 1918.61017 1935.32596 1952.45463 2147.05826 2237.70977 ## re_P[15,1] re_P[11,2] beta_1 re_P[38,1] re_P[28,2] re_P[24,2] re_P[22,1] re_P[41,1] re_P[34,1] re_P[17,1] re_P[19,2] re_P[33,2] re_P[46,2] re_P[30,1] ## 2271.94296 2341.05033 2409.66208 2450.97845 2484.29015 2582.74999 2655.35233 2744.59303 2804.56965 2817.08823 2946.91378 3053.89308 3072.84139 3079.35953 ## re_P[28,1] re_P[42,1] mu_0 re_P[24,1] re_P[50,2] re_P[4,1] re_P[8,2] re_P[27,1] re_P[6,2] re_P[31,2] re_P[16,2] re_P[48,1] re_P[47,1] re_P[48,2] ## 3086.61543 3093.66893 3099.31263 3102.17909 3155.10057 3281.12887 3332.35187 3341.73863 3413.23809 3454.37186 3493.73274 3587.41231 3591.42136 3675.56778 ## re_P[26,1] re_P[2,2] re_P[42,2] re_P[12,1] re_P[11,1] re_P[40,2] re_P[7,2] Pcor[2,2] re_P[40,1] re_P[44,1] re_P[7,1] re_P[21,1] re_P[46,1] re_P[47,2] ## 3702.03302 3751.75701 3808.74155 3831.23499 3909.43296 3921.53465 3951.96360 3979.81786 4014.31172 4089.20440 4092.73149 4165.15939 4202.21470 4249.42357 ## re_P[45,1] re_P[49,2] re_P[9,2] re_P[1,2] re_P[36,2] re_P[15,2] re_P[44,2] re_P[13,2] re_P[39,2] re_P[27,2] re_P[41,2] re_P[29,1] re_P[29,2] re_P[23,1] ## 4259.40189 4283.25174 4475.36683 4496.27577 4511.51724 4696.61656 4756.22902 4802.99606 4869.56377 4965.17029 4974.73710 5082.02783 5101.26920 5219.56301 ## re_P[16,1] re_P[21,2] re_P[45,2] re_P[23,2] ## 5225.86062 5348.76544 5377.61000 5561.01680 It is typical that individual-specific trait values in re_P have relatively lower effective sample sizes than the population-level parameters of primary interest. More damningly, however, we also see an extremely low effective sample for lp__, which is the joint log density of the model (up to a constant internally defined scale factor). This provides further evidence that the model, as currently defined, is poorly identified. The key random effect SDs sd_P and variances V_P are also very poorly sampled, along with the residual SD sd_R and variance V_R. We could run the MCMC sampler for more iterations, increase the warm-up period, and change various other manual control settings. However, the deeper issue here is not that the model is formally mispecified but rather that we have inefficiently parametrized the model for sampling. 1.4.1 Cholesky decompositions Although the .stan file appropriately represents the formal model, it is programmed in such a way that the MCMC sampler has troubling sampling from the joint posterior distribution of the model. One of the first things we can do to increase efficiency is to reduce redundant computation over matrices in our model. This can be done with Cholesky decompositions. For any positive definite matrix \\(\\boldsymbol{\\Omega}\\), a Cholesky decomposition can be defined such that \\[\\boldsymbol{\\Omega} = \\boldsymbol{\\mathrm{L}_{\\Omega}} \\boldsymbol{\\mathrm{L}_{\\Omega}}^{\\mathrm{T}}\\] where \\(\\boldsymbol{\\mathrm{L}_{\\Omega}}\\) is a lower-triangular matrix and \\(^{\\mathrm{T}}\\) indicates matrix transposition. This property means that we can always do computations of reduced dimensionality on the lower-triangular matrix \\(\\boldsymbol{\\mathrm{L}_{\\Omega}}\\) and subsequently recover the full positive-definitive matrix \\(\\boldsymbol{\\Omega}\\) by post-multiplying \\(\\boldsymbol{\\mathrm{L}_{\\Omega}}\\) with its transpose. Stan provides many built-in functions for easily defining and manipulating Cholesky decomposed matrices, which we can use to reparametrize the .stan file. Comments are added below where Cholesky decompositions have been introduced. data { int&lt;lower=1&gt; N; int&lt;lower=1&gt; I; int&lt;lower=1&gt; id[N]; vector[N] x; vector[N] z; } parameters { real mu_0; real beta_1; cholesky_factor_corr[2] LPcor; //lower tri Cholesky of random effect cor matrix vector&lt;lower=0&gt;[2] sd_P; real&lt;lower=0&gt; sd_R; matrix[I,2] re_P; } transformed parameters { cholesky_factor_cov[2] LPcov = diag_pre_multiply(sd_P, LPcor); //Cholesky of random effect cov } model { vector[I] mu = col(re_P, 1); vector[I] beta = col(re_P, 2); z ~ normal(mu_0 + mu[id] + (beta_1 + beta[id]).*x, sd_R); for(i in 1:I) re_P[i] ~ multi_normal_cholesky([0,0], LPcov); //likelihood expecting Cholesky cov mu_0 ~ normal(0,1); beta_1 ~ normal(0,1); LPcor ~ lkj_corr_cholesky(2); //prior for Cholesky matrix to_vector(sd_P) ~ cauchy(0,1); sd_R ~ cauchy(0,1); } generated quantities { vector[2] V_P = sd_P .* sd_P; real V_R = sd_R * sd_R; corr_matrix[2] Pcor = LPcor*LPcor&#39; ; //multiply by transpose to get full cor matrix cov_matrix[2] Pcov = diag_matrix(V_P) * Pcor * diag_matrix(V_P); //full cov matrix The full covariance and correlation matrices are now specified in the generated quantities block. 1.4.2 Non-centered random effects Before running this model, we can also reparametrize the random effects to further enhance efficiency. Currently, we express the unobserved random effects in re_P as being generated from a distribution with unobserved lower Cholesky covariance matrix LPcov. While mathematically appropriate, this specification can make it difficult for the model to identify the scale of the random effects. An alternative but mathematically equivalent parametrization can be used to separate out the scale of the random effect deviations from the population-level (co)variances, which often will enhance model identification. Note that any normally distributed random variable \\(\\boldsymbol{z}\\) where \\[\\boldsymbol{z} \\sim \\mathrm{Normal}(0,\\sigma_z)\\] can also be expressed as a standard normal variable \\(z_{std}\\) scaled by the original SD \\[\\boldsymbol{z} \\equiv \\boldsymbol{z_{\\mathrm{std}}}\\sigma_z\\] \\[\\boldsymbol{z_{\\mathrm{std}}} \\sim \\mathrm{Normal}(0,1)\\] Similarly for a n x p matrix \\(\\boldsymbol{Z}\\) of p multivariate phenotypes with covariance matrix \\(\\boldsymbol{\\mathrm{C}}\\) \\[\\boldsymbol{Z} \\equiv \\boldsymbol{Z_{\\mathrm{std}}} \\boldsymbol{\\mathrm{L}_{\\boldsymbol{\\mathrm{C}}}}^{\\mathrm{T}}\\] \\[\\mathrm{vec}(\\boldsymbol{Z_{\\mathrm{std}}}) \\sim \\mathrm{MVNormal}(\\boldsymbol{0},\\boldsymbol{\\mathrm{I}})\\] where \\(\\boldsymbol{\\mathrm{L}_{\\boldsymbol{\\mathrm{C}}}}\\) is the lower-triangular Cholesky decomposition. Implementing this so-called non-centered parametrization is straightforward in Stan and can of course also be applied to correlation matrices. Building on the Cholesky decompositions added in the previous subsection, and using the ' symbol for the transpose function write(&quot; data { int&lt;lower=1&gt; N; int&lt;lower=1&gt; I; int&lt;lower=1&gt; id[N]; vector[N] x; vector[N] z; } parameters { real mu_0; real beta_1; cholesky_factor_corr[2] LPcor; vector&lt;lower=0&gt;[2] sd_P; real&lt;lower=0&gt; sd_R; matrix[I,2] std_P; //now matrix of standard normals (see priors below) } transformed parameters { matrix[I,2] re_P = std_P * diag_pre_multiply(sd_P,LPcor)&#39;; //non-centered parameterization } model { vector[I] mu = col(re_P, 1); vector[I] beta = col(re_P, 2); z ~ normal(mu_0 + mu[id] + (beta_1 + beta[id]).*x, sd_R); mu_0 ~ normal(0,1); beta_1 ~ normal(0,1); to_vector(std_P) ~ std_normal(); //new prior distribution over standard normal deviations LPcor ~ lkj_corr_cholesky(2); to_vector(sd_P) ~ cauchy(0,1); sd_R ~ cauchy(0,1); } generated quantities { vector[2] V_P = sd_P .* sd_P; real V_R = sd_R * sd_R; corr_matrix[2] Pcor = LPcor*LPcor&#39; ; cov_matrix[2] Pcov = diag_matrix(V_P) * Pcor * diag_matrix(V_P); }&quot;, &quot;mod1.stan&quot;) Note that the specification of the random effects has been greatly simplified with the non-centered parametrization. By separating out the scale of the deviations and the population-level (co)variances, it becomes unnecessary to directly specify the generative distribution of the full random effects as above. Instead, the full distribution is partitioned into three independent priors over the random effect standard normal deviations, SDs, and correlations, and the generative distribution of these values is specified directly through the scaling of the standard normals, i.e. re_P = std_P * diag_pre_multiply(sd_P,LP_cor)'=\\(\\boldsymbol{Z} \\equiv \\boldsymbol{Z_{\\mathrm{std}}} \\boldsymbol{\\mathrm{L}_{\\boldsymbol{\\mathrm{C}}}}^{\\mathrm{T}}\\) above. This should make the model much easier to sample from. library(rstan) mod1 = stan_model(&quot;mod1.stan&quot;) ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): &#39;C:/rtools40/usr/mingw_/bin/g++&#39; not found stan_results2 &lt;- sampling(mod1, data=stan_data, init = 0, warmup=1500, iter = 2500, chains=4, cores=4, control=list(adapt_delta=0.90) ) #extracts posterior estimates MCMCsamples &lt;- extract(stan_results2) The absence of warning messages indicates that our mathematically equivalent reparametrizations have enhanced the efficiency of the MCMC sampler. The posterior samples of the model can subsequently be extracted, summarized, visualized, and manipulated. E.g. post_beta_1 = MCMCsamples$beta_1 #extract population-level slope median(post_beta_1) #central tendency of posterior ## [1] 0.298844 mad(post_beta_1) #dispersion around central tendency ## [1] 0.1005995 quantile(post_beta_1, c(0.05,0.95)) #90% credible interval ## 5% 95% ## 0.1175790 0.4610247 sum(post_beta_1 &gt; 0)/length(post_beta_1) #posterior probability of + effect ## [1] 0.995 hist(post_beta_1) #MCMC approximation of posterior distribution We encourage the use of the shinystan R package for deeper inspection of model convergence and results with a GUI. In general, researchers should be skeptical of reporting results accompanied with sampler warnings and should seek to remove any diagnostic concerns prior to biological interpretation of the estimates. 1.5 Animal models The model presented above assumes a single set of individual-specific intercepts and slopes, as defined by the mu and beta vectors in the .stan file. For quantitative genetic analysis with an animal model, these phenotypic effects can be further decomposed into distinct genetic and permanent environmental trait values. In particular, we expand the random phenotypic deviations so that \\[ \\boldsymbol{\\mu_{\\mathrm{ }}} = \\boldsymbol{\\mu_{\\mathrm{A}}} + \\boldsymbol{\\mu_{\\mathrm{E}}}, \\quad \\boldsymbol{\\beta_{\\mathrm{ }}} = \\boldsymbol{\\beta_{\\mathrm{A}}} + \\boldsymbol{\\beta_{\\mathrm{E}}}\\] \\[ \\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}} \\\\ \\boldsymbol{\\beta_{\\mathrm{A}}} \\end{bmatrix} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}}) : \\boldsymbol{\\mathrm{G}} = \\begin{bmatrix} \\mathrm{Var}( \\boldsymbol{\\mu_{\\mathrm{A}}} ) &amp; \\mathrm{Cov}( \\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\beta_{\\mathrm{A}}}) \\\\ \\mathrm{Cov}(\\boldsymbol{\\beta_{\\mathrm{A}}}, \\boldsymbol{\\mu_{\\mathrm{A}}} ) &amp; \\mathrm{Var}( \\boldsymbol{\\beta_{\\mathrm{A}}} ) \\end{bmatrix} \\] \\[ \\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{E}}} \\\\ \\boldsymbol{\\beta_{\\mathrm{E}}} \\end{bmatrix} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{E}} \\otimes \\boldsymbol{\\mathrm{I}}) : \\boldsymbol{\\mathrm{E}} = \\begin{bmatrix} \\mathrm{Var}( \\boldsymbol{\\mu_{\\mathrm{E}}} ) &amp; \\mathrm{Cov}( \\boldsymbol{\\mu_{\\mathrm{E}}}, \\boldsymbol{\\beta_{\\mathrm{E}}}) \\\\ \\mathrm{Cov}(\\boldsymbol{\\beta_{\\mathrm{E}}}, \\boldsymbol{\\mu_{\\mathrm{E}}} ) &amp; \\mathrm{Var}( \\boldsymbol{\\beta_{\\mathrm{E}}} ) \\end{bmatrix} \\] where \\(\\boldsymbol{\\mathrm{A}}\\) is a positive-definite relatedness matrix derived from pedigree or molecular data. As we explain below, challenges arise when estimating such a model in Stan due to the difficulty of computing Kronecker products and the identification of genetic effects. 1.5.1 Simulate data We use a custom function pedfun to generate an appropriately sized, positive-definite matrix for data simulation, which has been modified from prior work by Thomson et al. (2018). This function is also utilized in the simulation code provided on the Github page. We supply basic demographic settings and generate \\(\\boldsymbol{\\mathrm{A}}\\), and we increase the sample size to N=300 to aid parameter estimate. #custom function library(MCMCglmm) library(Matrix) pedfun &lt;- function(popmin, popmax, ngenerations, epm, nonb, nids, I, missing=FALSE){ # get list of individuals and their generations gener&lt;-1:ngenerations genern &lt;- rep(1:ngenerations, times = nids) ID &lt;- 1:sum(nids) # runs on generation-by-generation basis for(i in 1:ngenerations){ id&lt;-ID[which(genern==i)] dam&lt;-rep(NA, nids[i]) sire&lt;-rep(NA, nids[i]) # randomly allocates sex (0 = male, 1 = female) sex&lt;-sample(c(0,1), length(id), replace=TRUE) # for first generation, no dams or sires are known # so remain NA if(i==1){ # combine into single data frame pedigree&lt;-data.frame(id=id, dam=dam, sire=sire, generation=i, sex=sex) } else if(i&gt;1){ # for all generations after first # list of all possible dams and sires # from previous generation pdams&lt;-pedigree$id[which(pedigree$generation==(i-1) &amp; pedigree$sex==1)] psires&lt;-pedigree$id[which(pedigree$generation==(i-1) &amp; pedigree$sex==0)] # determine number of pairs # depending on how many males and females # and the proportion of the population that is non-breeding npairs&lt;-min(length(pdams), length(psires)) - round(min(length(pdams), length(psires))*nonb) # selects breeding males and females pdams&lt;-pedigree$id[which(pedigree$generation==(i-1) &amp; pedigree$sex==1)] psires&lt;-pedigree$id[which(pedigree$generation==(i-1) &amp; pedigree$sex==0)] if(length(pdams)&lt;npairs | length(psires)&lt;npairs){ npairs&lt;-min(length(pdams), length(psires)) } # selects pairs from possible dams and sires pairs&lt;-data.frame(dam=sample(pdams, npairs, replace=FALSE), sire=sample(psires, npairs, replace=FALSE)) # gives each offspring their parental pair pairid&lt;-as.numeric(sample(rownames(pairs), length(id), replace=TRUE)) # gives each offspring their sex sex&lt;-sample(c(0,1), length(id), replace=TRUE) # put into dataframe format addped&lt;-data.frame(id=id, dam=pairs$dam[pairid], sire=pairs$sire[pairid], generation=i, sex=sex) # deals with extra-pair mating (if included) if(!is.null(epm)){ # for each individual, sample if they are extra pair # if 0 not extra pair # if 1 sire resampled from breeding population # if 2 dam resampled ext&lt;-sample(c(0,1,2), nrow(addped), replace=TRUE, prob = c(1-epm, epm/2, epm/2)) for(j in 1:nrow(addped)){ if(ext[j]&gt;0){ if(ext[j]==1){ addped$sire[j]&lt;-sample(psires,1,replace=TRUE) }else if (ext[j]==2){ addped$dam[j]&lt;-sample(pdams,1,replace=TRUE) } } } } # add new generation to the whole pedigree pedigree&lt;-rbind(pedigree, addped) } } ped &lt;- pedigree # make id&#39;s non-numeric ped$id&lt;-paste(&quot;ID&quot;,ped$id, sep=&quot;&quot;) ped$dam[which(!is.na(ped$dam))]&lt;-paste(&quot;ID&quot;,ped$dam[which(!is.na(ped$dam))], sep=&quot;&quot;) ped$sire[which(!is.na(ped$sire))]&lt;-paste(&quot;ID&quot;,ped$sire[which(!is.na(ped$sire))], sep=&quot;&quot;) ped$id&lt;-as.character(ped$id) ped$dam&lt;-as.character(ped$dam) ped$sire&lt;-as.character(ped$sire) IDs &lt;- sample(ped[ped$generation==ngenerations, &quot;id&quot;], I, replace=FALSE) ped &lt;- prunePed(ped, keep = IDs, make.base=TRUE) inv.phylo &lt;- inverseA(ped[,c(&quot;id&quot;,&quot;dam&quot;,&quot;sire&quot;)]) A &lt;- solve(inv.phylo$Ainv) A &lt;- cov2cor(A) A = (A + t(A))/2 # Not always symmetric after inversion A &lt;- as.matrix(A) rownames(A) &lt;- rownames(inv.phylo$Ainv) colnames(A) &lt;- rownames(inv.phylo$Ainv) #subset to final generation A_sub&lt;-A[IDs,IDs] A_mat &lt;- as.matrix(nearPD(A_sub)$mat) A_mat &lt;- cov2cor(A_mat) return(A_mat) } #population properties I=300 #total individuals for simulation popmin=400 popmax=600 ngenerations = 10 nids&lt;-sample(popmin:popmax, ngenerations, replace=TRUE) #N / generation epm = sample(seq(0.15, 0.25,by=0.05),1) #extra-pair mating nonb = sample(seq(0.4,0.6,by=0.05),1) #proportion of non-breeding / generation #relatedness matrix A_mat &lt;- pedfun(popmin=popmin, popmax=popmax, ngenerations=ngenerations, epm=epm, nonb=nonb, nids=nids, I=I, missing=FALSE) We can now simulate a new dataset using the code from above, partitioning the distinct additive genetic and permanent environmental trait values. We include a third measurement per individual to enhance estimation of the individual-level RN intercepts and slopes. library(mvtnorm) N = 900 #total observations (3x/individual) I = 300 #total individuals intercept = 1 #global intercept beta1 = 0.3 #fixed effect regression coefficient SD_intercept = 0.3 #standard deviation of random intercepts SD_slope = 0.3 SD_residual = 1 r_G = 0.5 #genetic correlation of random intercepts and slopes r_E = -0.5 #environmental correlation V_G = 0.3 #genetic variance of REs V_E = 0.3 #genetic variance of REs #Random effect correlations G_cor &lt;- matrix(c(1,r_G,r_G,1), nrow=2, ncol=2) #mu_A, beta_A G_sd &lt;- c(sqrt(V_G),sqrt(V_G)) #G effect sds G_cov &lt;- diag(G_sd) %*% G_cor %*% diag(G_sd) E_cor &lt;- matrix(c(1,r_E,r_E,1), nrow=2, ncol=2) #mu_E, beta_E E_sd &lt;- c(sqrt(V_E),sqrt(V_E)) #E effect sds E_cov &lt;- diag(E_sd) %*% E_cor %*% diag(E_sd) #matrices G_block &lt;- G_cov %x% A_mat E_block &lt;- E_cov %x% diag(1,I) #generate correlated REs Gvalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=G_block) G_val = data.frame(matrix(Gvalues, nrow=I, ncol=2)) cor(G_val) ## X1 X2 ## X1 1.0000000 0.5049964 ## X2 0.5049964 1.0000000 Evalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=E_block) E_val = data.frame(matrix(Evalues, nrow=I, ncol=2)) cor(E_val) ## X1 X2 ## X1 1.0000000 -0.5204793 ## X2 -0.5204793 1.0000000 #combine re_P = cbind(G_val,E_val) colnames(re_P) = c(&quot;mu_A&quot;, &quot;beta_A&quot;, &quot;mu_E&quot;, &quot;beta_E&quot;) #individual-level index id = rep(seq(1, I), each = N/I) #i.e. two observations per individual #simulate fixed effect covariate x = rnorm(N,0,1) #individual phenotypic REs mu = re_P$mu_A + re_P$mu_E beta = re_P$beta_A + re_P$beta_E #residual effects epsilon = rnorm(N, 0, SD_residual ) #measured response z = intercept + mu[id] + (beta1 + beta[id])*x + epsilon #combine into list for Stan stan_data = list(z = z, x = x, id = id, N = N, I = I, A = A_mat) 1.5.2 Kronecker products We now need to edit the Stan file to partition the genetic and environmental values. Unfortunately, there are no in-built Stan functions for efficiently computing Kronecker products \\(\\otimes\\). This could be overcome by manually specifying the Kronecker product function in the optional functions block of the model. However, Kronecker products can be incredibly costly to compute, particularly for large matrices. Its thus desirable to find another alternative but mathematically equivalent parametrization to return random effects appropriately scaled by \\(\\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}}\\) without directly computing this term, as we did above with the Cholesky decomposition and non-centered random effects. Fortunately, this can be easily accomplished by exploiting the properties of the matrix normal distribution, which generalizes the multivariate normal distribution to random variables described by matrices (Gupta and Nagar 2018). In particular, the matrix normal distribution for some n x p matrix \\(\\boldsymbol{\\mathrm{Z}}\\) of p phenotypes is given by \\[ \\boldsymbol{\\mathrm{Z}} \\sim \\mathrm{Matrix\\ Normal_{n \\ x \\ p}}(\\boldsymbol{\\mathrm{M}}, \\boldsymbol{\\mathrm{U}}, \\boldsymbol{\\mathrm{V}}) \\] where \\(\\boldsymbol{\\mathrm{M}}\\) is a matrix of expected values and \\(\\boldsymbol{\\mathrm{U}}\\) and \\(\\boldsymbol{\\mathrm{V}}\\) are scaling matrices describing the among-row and among-column (co)variance respectively. This lesser known distribution generalizes from the multivariate normal distribution such that any matrix \\(\\boldsymbol{\\mathrm{Z}}\\) will be matrix normally distributed if and only if \\[ \\mathrm{vec}(\\boldsymbol{\\mathrm{Z}}) \\sim \\mathrm{MVNormal_{np}}(\\mathrm{vec}(\\boldsymbol{\\mathrm{M}}), \\boldsymbol{\\mathrm{V}} \\otimes \\boldsymbol{\\mathrm{U}} ) \\] where \\(\\mathrm{vec}()\\) is the vector operator, as used above in the mod1.stan file. Given that we are interested in generating random effects with covariance \\(\\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}}\\), direct computation of the Kronecker product can be avoided by instead sampling the random effects from a matrix normal distribution with the appropriate scaling matrices, i.e. for the for the I x 2 matrix of additive genetic intercepts and slope deviations for I individuals \\[ \\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}} &amp; \\boldsymbol{\\beta_{\\mathrm{A}}} \\end{bmatrix} \\sim \\mathrm{Matrix\\ Normal_{I \\ x \\ 2}}(\\boldsymbol{\\mathrm{0}}, \\boldsymbol{\\mathrm{A}}, \\boldsymbol{\\mathrm{G}}) \\] We can use the non-centered parameterization described above for the multivariate normal distribution to also more efficiently sample from this matrix normal distribution. In particular, a matrix \\(\\boldsymbol{\\mathrm{Z_{_{I \\ x \\ 2}}}}\\) can be defined for I individual standard normal deviations on each of 2 random effects, which are distributed such that \\[\\boldsymbol{\\mathrm{Z_{std}}} \\sim \\mathrm{Matrix\\ Normal_{I \\ x \\ 2}}(\\boldsymbol{\\mathrm{0}}, \\boldsymbol{\\mathrm{I}}, \\boldsymbol{\\mathrm{I}}) \\] The desired matrix of appropriately scaled, zero-centered random effects can then be defined such that \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}} &amp; \\boldsymbol{\\beta_{\\mathrm{A}}} \\end{bmatrix} = \\boldsymbol{0}+\\boldsymbol{\\mathrm{L_A}} \\boldsymbol{\\mathrm{Z_{std}}} \\boldsymbol{\\mathrm{L_G}}^{\\mathrm{T}}\\] where \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}} &amp; \\boldsymbol{\\beta_{\\mathrm{A}}} \\end{bmatrix} \\sim \\mathrm{Matrix\\ Normal_{I \\ x \\ 2}}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{L_A}} \\boldsymbol{\\mathrm{L_A}}^{\\mathrm{T}}, \\boldsymbol{\\mathrm{L_G}} \\boldsymbol{\\mathrm{L_G}}^{\\mathrm{T}} )\\] As explained above, \\(\\boldsymbol{\\mathrm{L_A}}\\) is the lower triangular Cholesky decomposition of the \\(\\boldsymbol{\\mathrm{A}}\\) matrix, while \\(\\boldsymbol{\\mathrm{L_G}}^{\\mathrm{T}}\\) is the transpose of the lower triangular Cholesky decomposition of the \\(\\boldsymbol{\\mathrm{G}}\\) covariance matrix. This sampling property of the matrix normal distribution therefore facilitates sampling from \\[ \\mathrm{vec}( \\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}} &amp; \\boldsymbol{\\beta_{\\mathrm{A}}} \\end{bmatrix} ) \\sim \\mathrm{MVNormal_{np}}(\\mathrm{vec}(\\boldsymbol{\\mathrm{0}}), \\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}} )\\] through the multiplication of the \\(\\boldsymbol{\\mathrm{Z_{std}}}\\), \\(\\boldsymbol{\\mathrm{L_A}}\\), and \\(\\boldsymbol{\\mathrm{L_G}}^{\\mathrm{T}}\\) matrices. This useful sampling property is straightforward to implement in Stan with appropriate data and can be used to account for any form of random effect covariation among individuals, which may extend beyond \\(\\boldsymbol{\\mathrm{A}}\\) alone. Thomson et al. (2018) provide an extensive review of various additional sources of autocorrelation that should be considered in quantitative genetic analyses. Note that this matrix normal approach is key to efficient estimation of the SAM as well, as demonstrated in the subsequent tutorials. Here we review the relevant code in Stan to highlight how any Kronecker product could be implemented more generally. The code of mod1.stan can be modified accordingly, so that the basic linear mixed-effects model for phenotypic analysis becomes a linear animal model for quantitative genetic analysis. The relatedness matrix \\(\\boldsymbol{{\\mathrm{A}}}\\) is now declared in the data block, while the lower triangle Cholesky decomposition matrix \\(\\boldsymbol{\\mathrm{L_A}}\\) is generated in the transformed data block. data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; I; int&lt;lower=0&gt; id[N]; vector[N] x; vector[N] z; matrix[I,I] A; //new relatedness matrix } transformed data{ matrix[I,I] LA = cholesky_decompose(A); //lower triangle relatedness matrix } New parameters are also declared for the separate genetic (G) and permanent environmental (E) effects. parameters { //fixed effects real mu_0; real beta_1; //random effects cholesky_factor_corr[2] LGcor; //LC genetic correlation matrix cholesky_factor_corr[2] LEcor; //LC permanent environmental correlation matrix vector&lt;lower=0&gt;[2] sd_G; //SD of genetic effects vector&lt;lower=0&gt;[2] sd_E; //SD of environmental effects real&lt;lower=0&gt; sd_R; matrix[I,2] std_G; //matrix of standard normals for G effects matrix[I,2] std_E; //matrix of standard normals for E effects } The appropriately scaled random deviations can then be specified in the transformed parameters block. The matrix normal parametrization, i.e. \\(\\left[ \\boldsymbol{\\mu_A}, \\boldsymbol{\\beta_A}\\right] =0+\\mathrm{L_A}\\mathrm{Z_{std_G}}(\\mathrm{G_{sd}}\\mathrm{L}_{G_{cor}})^{\\mathrm{T}}\\) where \\(\\mathrm{G_{sd}}\\mathrm{L}_{G_{cor}}=\\mathrm{L}_{G_{}}\\) is the lower Cholesky covariance matrix, is required for the additive genetic random effects, while the simpler non-centered approach may instead be used for the permanent environmental effects that are independently distributed among individuals. The ' function can again be used to return the transpose of the Cholesky decomposed covariance matrices in Stan. transformed parameters { matrix[I,2] re_G = LA * std_G * diag_pre_multiply(sd_G,LGcor)&#39; ; //matrix normal matrix[I,2] re_E = std_E * diag_pre_multiply(sd_E,LEcor)&#39;; //non-centered vector[I] mu = col(re_G, 1) + col(re_E, 1); //P = G + E vector[I] beta = col(re_G, 2) + col(re_E, 2); //P = G + E } With the addition of new priors in the model block to_vector(std_devG) ~ std_normal(); //standard normal deviates to_vector(std_devE) ~ std_normal(); LGcor ~ lkj_corr_cholesky(2); LEcor ~ lkj_corr_cholesky(2); to_vector(sd_G) ~ cauchy(0,1); to_vector(sd_E) ~ cauchy(0,1); the model will be well defined and equivalent to the simpler formal model defined with Kronecker products of covariance matrices. Note that the permanent environmental effects are defined as they were for the purely phenotypic effects above, without consideration of the Kronecker product \\(\\boldsymbol{\\mathrm{E}}\\otimes\\boldsymbol{\\mathrm{I}}\\). This product indicates that individuals trait values are independent and identically distributed, so that ignoring the Kronecker product in Stan with re_E = std_E * diag_pre_multiply(sd_E,LEcor)' is equivalent to specifying the matrix normal parameterization with additional Cholesky identity matrix \\(\\boldsymbol{\\mathrm{L_{I}}}\\), i.e. re_E = LI * std_E * diag_pre_multiply(sd_E,LE_cor)'. 1.5.3 Identifying genetic effects This matrix normal approach makes the animal model computationally efficient, but a more fundamental issue remains for identifying the scales of the distinct \\(\\boldsymbol{\\mathrm{G}}\\) and \\(\\boldsymbol{\\mathrm{E}}\\) effects during model estimation. Given that \\(\\boldsymbol{\\mathrm{P}}=\\boldsymbol{\\mathrm{G}} + \\boldsymbol{\\mathrm{E}}\\) under the assumption of independent additive effects, it can be difficult to uniquely identify the scale of the distinct genetic and environmental trait values, as any increase/decrease in genetic trait values can be compensated by an equivalent decrease/increase in the environmental trait value to achieve equivalent phenotypic values. In principle, this issue is addressed by the fixed information in \\(\\boldsymbol{\\mathrm{A}}\\) that is provided to the model prior to estimation. In reality, however, relatedness matrices in the wild are often quite sparse, with most elements at or near 0. As a consequence, when a single individual-level parameter is expressed as the sum of two distinct parameters, as differentiated by the scaling of \\(\\boldsymbol{\\mathrm{A}}\\) and \\(\\boldsymbol{\\mathrm{I}}\\), it can be challenging to identify the proportion of variance attributable to each effect. Note that in the simplest case of completely unrelated individuals, i.e. \\(\\boldsymbol{\\mathrm{A}} = \\boldsymbol{\\mathrm{I}}\\), genetic and environmental effects are completely confounded and cannot be uniquely identified without introducing further assumptions, as any combination of genetic and environmental values summing to the same value will fit the data equally well. Fortunately, in spite of the empirical reality of sparse relatedness matrices, it is possible to parameterize an animal model in Stan so that even weakly identified genetic effects can be disentangled from environmental effects, using whatever information is provided by the fixed relatedness matrix and empirical data. This is accomplished by re-expressing the scale of the \\(\\boldsymbol{\\mathrm{G}}\\) and \\(\\boldsymbol{\\mathrm{E}}\\) effects not as independent parameters, but rather as dependent variances derived from their proportion of a common phenotypic variance parameter. In other words, the model only has to identify the scale of the total phenotypic trait values rather than attempting to identify two independent but potentially confounded random effect variances, i.e. \\[\\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{ }}) = \\frac { \\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{A}}}) }{\\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{P}}})}\\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{ }}) + \\frac { \\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{E}}}) }{\\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{P}}})}\\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{ }})\\] \\[\\mathrm{Var}(\\boldsymbol{\\beta_\\mathrm{ }}) = \\frac { \\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{A}}}) }{\\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{ }}})}\\mathrm{Var}(\\boldsymbol{\\beta_\\mathrm{ }}) + \\frac { \\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{E}}}) }{\\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{P}}})}\\mathrm{Var}(\\boldsymbol{\\beta_\\mathrm{ }})\\] The additive genetic proportions can be conceptualized as reaction norm heritabilities for the intercept and slope parameters \\[h_{\\mu}^{2} =\\frac { \\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{A}}}) }{\\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{ }}})}\\] \\[h_{\\beta}^{2}=\\frac { \\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{A}}}) }{\\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{ }}})}\\] Given that there are only two individual-level random effects, the proportion of variance attributable to environmental effects is necessarily \\(1-h_{\\mu}^{2}\\) and \\(1-h_{\\beta}^{2}\\) for intercepts and slopes respectively. This alternative parametrization is again mathematically equivalent to the previous model, but it is much easier for Stan to estimate appropriately. To implement this trick, we respecify the model parameters, removing the distinct genetic and environmental SDs and replacing them with common phenotypic SD scale parameters and reaction norm heritability parameters, which can subsequently be used to scale the distinct genetic and environmental standard normal deviates and correlation matrices in the transformed parameters block. This final model can thus be written as write(&quot; data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; I; int&lt;lower=0&gt; id[N]; vector[N] x; vector[N] z; matrix[I,I] A; //new relatedness matrix } transformed data{ matrix[I,I] LA = cholesky_decompose(A); //lower triangle relatedness matrix } parameters { //fixed effects real mu_0; real beta_1; //random effects cholesky_factor_corr[2] LGcor; //additive genetic cor matrix cholesky_factor_corr[2] LEcor; //permanent environmental cor matrix vector&lt;lower=0&gt;[2] sd_P; //total phenotypic SD (removed distinct G and E SDs) real&lt;lower=0&gt; sd_R; matrix[I,2] std_G; //matrix of standard normals for G effects matrix[I,2] std_E; //matrix of standard normals for E effects //RN heritability (proportion between 0 and 1) vector&lt;lower=0,upper=1&gt;[2] RN_h2; } transformed parameters { vector&lt;lower=0&gt;[2] sd_G; //SDs of G effects vector&lt;lower=0&gt;[2] sd_E; //SDs of E effects matrix[I,2] re_G; //scaled G random effects matrix[I,2] re_E; //scaled E random effects vector[I] mu; //phenotypic individual intercepts vector[I] beta; //phenotypic individual slopes //SDs of genetic effects, sqrt(phenotypic variance * h2) sd_G[1] = sd_P[1] * sqrt(RN_h2[1]); //genetic SD for ind intercepts sd_G[2] = sd_P[2] * sqrt(RN_h2[2]); //genetic SD for ind slopes //SDs of environmental effects, sqrt(phenotypic variance * [1-h2]) sd_E[1] = sd_P[1] * sqrt(1 - RN_h2[1]); //environment SD for ind intercepts sd_E[2] = sd_P[2] * sqrt(1 - RN_h2[2]); //environment SD for ind slopes //matrix normal parameterization re_G = LA * std_G * diag_pre_multiply(sd_G, LGcor)&#39; ; //non-centered parameterization re_E = std_E * diag_pre_multiply(sd_E, LEcor)&#39; ; //separate intercepts and slopes mu = col(re_G, 1) + col(re_E, 1); //P = G + E beta = col(re_G, 2) + col(re_E, 2); //P = G + E } model { //model likelihood z ~ normal(mu_0 + mu[id] + (beta_1 + beta[id]).*x, sd_R); //priors //fixed effects mu_0 ~ normal(0,1); beta_1 ~ normal(0,1); //random effects to_vector(std_G) ~ std_normal(); //genetic std normal deviates to_vector(std_E) ~ std_normal(); //environmental std normal deviates LGcor ~ lkj_corr_cholesky(2); //genetic correlations LEcor ~ lkj_corr_cholesky(2); //environmental correlations to_vector(sd_P) ~ cauchy(0,1); //only phenotypic scale sd_R ~ cauchy(0,1); //reaction norm heritability to_vector(RN_h2) ~ beta(1.2,1.2); } generated quantities { corr_matrix[2] Gcor = LGcor * LGcor&#39;; //genetic cor corr_matrix[2] Ecor = LEcor * LEcor&#39;; //environmental cor matrix[2,2] Gcov = diag_matrix(sd_G)*Gcor*diag_matrix(sd_G); //genetic cov matrix[2,2] Ecov = diag_matrix(sd_E)*Ecor*diag_matrix(sd_E); //environmental cov matrix[2,2] Pcov = Gcov + Ecov; //phenotypic covariance (assuming independent effects) matrix[2,2] Pcor = inverse(diag_matrix(sd_P))*Pcov*inverse(diag_matrix(sd_P)); //phenotypic cor //variances vector&lt;lower=0&gt;[2] V_P = sd_P .* sd_P; vector&lt;lower=0&gt;[2] V_G = sd_G .* sd_G; vector&lt;lower=0&gt;[2] V_E = sd_E .* sd_E; real V_R = sd_R * sd_R; }&quot;, &quot;mod1_QG.stan&quot;) Note that because we specify phenotypic SDs sd_P, the genetic SDs sd_G are calculated as \\(\\mathrm{sqrt} ({\\mathrm{Var}(\\boldsymbol{\\mu_{\\mathrm{}}})}h_{\\mu}^{2})= {\\mathrm{SD}(\\boldsymbol{\\mu_{\\mathrm{}}})}\\mathrm{sqrt}(h_{\\mu}^{2})\\) and \\(\\mathrm{sqrt} ({\\mathrm{Var}(\\boldsymbol{\\beta_{\\mathrm{}}})}h_{\\beta}^{2})= {\\mathrm{SD}(\\boldsymbol{\\beta_{\\mathrm{}}})}\\mathrm{sqrt}(h_{\\beta}^{2})\\), with the same approach taken for the proportion of environmental effects \\(1- h_{\\mu}^{2}\\) and \\(1-h_{\\beta}^{2}\\). A weakly regularizing \\(\\mathrm{Beta}(1.2,1.2)\\) prior is placed on the reaction norm heritability parameters, which are constrained between 0 and 1. This and any other prior can be easily visualized in R by randomly sampling from the relevant distribution. hist( rbeta(1e5, 1.2, 1.2), prob = TRUE ) This prior is therefore relatively flat and uninformative over the range of plausible values, but provides very weak regularization by giving lower relative probability at the extreme ends approaching 0 (no genetic effect) and 1 (complete genetic effect). With more than two individual-level random effects, such as when specifying multiple matrices of individual autocorrelation (Thomson et al. 2018), SDs and variances can instead be parameterized as scaled simplexes. We can now estimate our animal model in Stan. library(rstan) mod1_QG = stan_model(&quot;mod1_QG.stan&quot;) ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): &#39;C:/rtools40/usr/mingw_/bin/g++&#39; not found stan_resultsQG &lt;- sampling(mod1_QG, data=stan_data, init = 0, warmup=1500, iter = 4500, chains=4, cores=4, control=list(adapt_delta=0.90) ) #extracts posterior estimates post = extract(stan_resultsQG) Lets see how well we recovered the genetic and environmental (co)variances of the reaction norm parameters. Due to random sampling and our relatively small sample size, we should anticipate noisy estimates. #RN intercepts [1] and slopes [2] apply(post$V_P, 2, median) #phenotypic variance ## [1] 0.5667144 0.6803903 apply(post$V_G, 2, median) #genetic variance ## [1] 0.2293415 0.2582903 apply(post$V_E, 2, median) #environmental variance ## [1] 0.3267623 0.4061270 #RN intercept and slope correlation median(post$Pcor[,1,2]) #phenotypic corr ## [1] 0.01690476 median(post$Gcor[,1,2]) #genetic corr ## [1] 0.08791329 median(post$Ecor[,1,2]) #environmental corr ## [1] -0.02310427 Resources "],["within-partner-sam.html", "2 Within partner SAM 2.1 Formal overview 2.2 Computational approach 2.3 Simulate data 2.4 Coding the model 2.5 Estimating the model 2.6 Failure to detect assortment 2.7 Phenotypic model", " 2 Within partner SAM SAMs build on the Stan code we used for a basic animal model (1.5) in three key ways: (i) by implementing an autoregressive moving average (ARMA) function between the social reaction norms (SRNs) of individuals and their partners, (ii) within-individual centering of SRNs, and (iii) estimating selection gradients on SRN parameters. Note that (ii) is only applicable to study designs in which individuals are measured across multiple partners, and thus does not apply to the within partner model presented here. As is explained below, this model can effectively estimate social plasticity (SRN slopes) but does not effectively estimate assortment, due to confounding in the absence of multiple partners (2.6). The fitness model addressing (iii) is handled in a subsequent chapter ((??)). The theoretical and statistical motivation behind each of these extensions is explained in detail by Martin and Jaeggi (2021). After estimating a SAM, we also want to extract the model posteriors and subsequently estimate the assortment matrix \\(\\boldsymbol{\\mathrm{B_{\\alpha}}}\\), the selection gradients \\(\\mathrm{s_{\\mu}}\\) and \\(\\mathrm{s_{\\psi}}\\), and the responses to selection \\(\\Delta \\bar{\\mathrm{\\mu}}\\) and \\(\\Delta \\bar{\\mathrm{\\psi}}\\). Here we provide a tutorial for the within-partner SAM, presented as Eq 3.1 in Martin and Jaeggi (2021), which is appropriate for sampling designs where each individual is measured interacting with a single partner over multiple time intervals, e.g. \\(t= \\left \\{ 1,2,3 \\right \\}\\) to index the first, second, and third observation of a focal individual with the same social partner. For clarity, we focus on the simple linear models presented in the paper, largely ignoring complications such as the inclusion of additional random and fixed effects for adjusting estimates, which can be accomplished using basic approaches for any Stan model. See the Stan Reference Manual and Stan Case Studies for further details. The detailed coding tutorials in Chapter 1 are also crucial for understanding the Cholesky decompositions, reaction norm heritabilities, and non-centered and matrix normal parametrizations used below, which we do not review again in detail. 2.1 Formal overview The formal model for a measurement of aggression \\(z_{jt}\\) in focal individual \\(j\\) at time \\(t\\) is given by \\[z_{jt} = \\mu_0 + \\eta_{jt} + \\xi_{jt}\\] \\[\\eta_{jt} = \\begin{Bmatrix} \\mu_j + \\left( \\psi_1 + \\psi_j \\right)\\mu_k&#39; &amp; \\mathrm{if} \\ t = 1 \\\\ \\mu_j + \\left( \\psi_1 + \\psi_j \\right)\\eta_{kt-1}&#39; &amp; \\mathrm{else} \\end{Bmatrix} \\] \\[\\xi_{jt} = \\begin{Bmatrix} \\epsilon_{jt} &amp; \\mathrm{if} \\ t = 1 \\\\ \\epsilon_{jt} + \\phi\\epsilon_{kt-1}&#39; &amp; \\mathrm{else} \\end{Bmatrix} \\] \\[\\mu_j = \\mu_{\\mathrm{A}j} + \\mu_{\\mathrm{E}j}, \\quad \\psi_j = \\psi_{\\mathrm{A}j} + \\psi_{\\mathrm{E}j}\\] with the equivalent specification for the social partners aggression measure \\(z_{kt}&#39;\\) \\[z_{kt}&#39; = \\mu_0 + \\eta_{kt}&#39; + \\xi_{kt}&#39;\\] \\[\\eta_{kt}&#39; = \\begin{Bmatrix} \\mu_k&#39; + \\left( \\psi_1 + \\psi_k&#39; \\right)\\mu_j &amp; \\mathrm{if} \\ t = 1 \\\\ \\mu_k&#39; + \\left( \\psi_1 + \\psi_k&#39; \\right)\\eta_{jt-1} &amp; \\mathrm{else} \\end{Bmatrix} \\] \\[\\xi_{kt}&#39; = \\begin{Bmatrix} \\epsilon_{kt}&#39; &amp; \\mathrm{if} \\ t = 1 \\\\ \\epsilon_{kt}&#39; + \\phi\\epsilon_{jt-1} &amp; \\mathrm{else} \\end{Bmatrix} \\] \\[\\mu_k&#39; = \\mu_{\\mathrm{A}k}&#39; + \\mu_{\\mathrm{E}j}&#39;, \\quad \\psi_k&#39; = \\psi_{\\mathrm{A}k}&#39; + \\psi_{\\mathrm{E}k}&#39;\\] The random effects are assumed to be well-described by multivariate normal distributions. \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\mu&#39;_{\\mathrm{A}}},\\boldsymbol{\\psi_{\\mathrm{A}}},\\boldsymbol{\\psi}&#39;_{\\mathrm{A}} \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}} ) \\] \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{E}}}, \\boldsymbol{\\mu&#39;_{\\mathrm{E}}},\\boldsymbol{\\psi_{\\mathrm{E}}},\\boldsymbol{\\psi}&#39;_{\\mathrm{E}} \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{E}} \\otimes \\boldsymbol{\\mathrm{I}} ) \\] \\[\\begin{bmatrix} \\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon}&#39; \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{\\Sigma}} ) \\] We also assume that the social reaction norm (SRN) intercept and slope (co)variances are equivalent for focal (\\(\\boldsymbol{\\mu},\\boldsymbol{\\psi}\\)) and social partners (\\(\\boldsymbol{\\mu}&#39;,\\boldsymbol{\\psi}&#39;\\)). The G matrix can therefore be reduced to a 2x2 matrix for all individuals in the population \\[\\boldsymbol{\\mathrm{G}}= \\begin{bmatrix} \\mathrm{var([\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;])} &amp; \\mathrm{cov([\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;],[\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;])} \\\\ \\mathrm{cov([\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;],[\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;])} &amp; \\mathrm{var([\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;])} \\end{bmatrix}\\] The residual matrix \\(\\boldsymbol{\\Sigma}\\), however, estimates separate variances and covariances for the focal and partner residuals, which allows the model to account for residual covariance and feedback effects (collectively referred to as SRN measurement errors \\(\\boldsymbol{\\xi}\\) and \\(\\boldsymbol{\\xi}&#39;\\)). \\[\\boldsymbol{\\Sigma}= \\begin{bmatrix} \\mathrm{var(\\boldsymbol{\\epsilon})} &amp; \\mathrm{cov}(\\boldsymbol{\\epsilon},\\boldsymbol{\\epsilon}&#39;) \\\\ \\mathrm{cov}(\\boldsymbol{\\epsilon}&#39;,\\boldsymbol{\\epsilon}) &amp; \\mathrm{var(\\boldsymbol{\\epsilon&#39;})} \\end{bmatrix}\\] This model is, therefore, appropriate for situations where the distinction between focal and partner is semi-arbitrary, e.g. when measuring within-sex interactions or when males and females exhibit similar patterns of phenotypic variation. In this case, we make the latter assumption for simplicity. To account for differences between the responses of focal individuals and social partners, the model can simply be extended with additional parameters, e.g. specifying separate \\(G_M\\) and \\(G_F\\) matrices for males and female respective genetic (co)variances and so on. 2.2 Computational approach As shown in Chapter 1, we can express the formal model above in a mathematically equivalent but more computationally efficient manner by decomposing the covariance matrices into matrices of correlations and SDs, using lower triangular Cholesky decompositions on the correlation matrices. For example, the genetic covariance is given by \\[\\boldsymbol{\\mathrm{G}}_{cov}= \\boldsymbol{\\mathrm{G}_{sd}} \\boldsymbol{\\mathrm{G}}_{cor} \\boldsymbol{\\mathrm{G}_{sd}}\\] \\[\\boldsymbol{\\mathrm{G}}_{cor} = \\boldsymbol{\\mathrm{L}}_{Gcor} \\boldsymbol{\\mathrm{L}}_{Gcor}^{\\mathrm{T}} = \\begin{bmatrix} 1 &amp; \\mathrm{cor}([\\boldsymbol{\\mu},\\boldsymbol{\\mu&#39;}],[\\boldsymbol{\\psi},\\boldsymbol{\\psi&#39;}] ) \\\\ \\mathrm{cor}([\\boldsymbol{\\psi},\\boldsymbol{\\psi&#39;}], [\\boldsymbol{\\mu},\\boldsymbol{\\mu&#39;}] ) &amp; 1 \\end{bmatrix}\\] \\[\\boldsymbol{\\mathrm{G}_{sd}}=\\begin{bmatrix} \\mathrm{sd}([\\boldsymbol{\\mu},\\boldsymbol{\\mu&#39;}]) &amp; 0 \\\\ 0 &amp; \\mathrm{sd}([\\boldsymbol{\\psi},\\boldsymbol{\\psi&#39;}]) \\end{bmatrix}\\] The estimation of the Kronecker product \\(\\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}}\\) is achieved through sampling of a non-centered matrix normal distribution \\[\\begin{bmatrix} [\\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\mu_{\\mathrm{A}}}&#39;]^{\\mathrm{T}} &amp; [\\boldsymbol{\\psi_{\\mathrm{A}}}, \\boldsymbol{\\psi_{\\mathrm{A}}}&#39;]^{\\mathrm{T}} \\end{bmatrix} = \\boldsymbol{L_{\\mathrm{A}}} \\begin{bmatrix} [\\boldsymbol{\\mu_{\\mathrm{A.std}}}, \\boldsymbol{\\mu_{\\mathrm{A.std}}}&#39;]^{\\mathrm{T}} &amp; [\\boldsymbol{\\psi_{\\mathrm{A.std}}}, \\boldsymbol{\\psi_{\\mathrm{A.std}}}&#39;]^{\\mathrm{T}} \\end{bmatrix} (\\boldsymbol{\\mathrm{G}_{sd}}\\boldsymbol{\\mathrm{L}_{Gcor}})^{\\mathrm{T}} \\] which is appropriate for estimating values drawn from \\[\\begin{bmatrix}[\\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\mu_{\\mathrm{A}}}&#39;]^{\\mathrm{T}} &amp; [\\boldsymbol{\\psi_{\\mathrm{A}}}, \\boldsymbol{\\psi_{\\mathrm{A}}}&#39;]^{\\mathrm{T}} \\end{bmatrix} \\sim \\mathrm{Matrix\\ Normal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{L_A}} \\boldsymbol{\\mathrm{L_A}}^{\\mathrm{T}}, \\boldsymbol{\\mathrm{L_{Gcov}}} \\boldsymbol{\\mathrm{L_{Gcov}}}^{\\mathrm{T}} ) \\equiv \\\\ \\mathrm{vec}( \\begin{bmatrix} [\\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\mu_{\\mathrm{A}}}&#39;]^{\\mathrm{T}} &amp; [\\boldsymbol{\\psi_{\\mathrm{A}}}, \\boldsymbol{\\psi_{\\mathrm{A}}}&#39;]^{\\mathrm{T}} \\end{bmatrix}) \\sim \\mathrm{MVNormal}(\\mathrm{vec}(\\boldsymbol{\\mathrm{0}}), \\boldsymbol{\\mathrm{G_{cov}}} \\otimes \\boldsymbol{\\mathrm{A}} ) \\] The environmental effects are estimated with a standard non-centered multivariate normal parametrization \\[\\mathrm{SRN}_{\\mathrm{E}}=\\left[ \\boldsymbol{\\mu_{\\mathrm{E}}} \\ \\boldsymbol{\\mu_{\\mathrm{E}}}&#39; \\right]=\\left[ \\boldsymbol{\\mu_{\\mathrm{E.std}}} \\ \\boldsymbol{\\mu_{\\mathrm{E.std}}}&#39; \\right] (\\boldsymbol{\\mathrm{E}_{sd}}\\boldsymbol{\\mathrm{L}_{Ecor}})^{\\mathrm{T}} \\] The \\(\\mathrm{std}\\) values are standard normal deviates, i.e. \\(\\mathrm{std~\\sim Normal}(0, 1)\\), that are scaled to appropriate (co)variance through the separated SD and correlation parameters. For Bayesian estimation, we place very weakly regularizing priors on the fixed population intercept, slope, and residual feedback parameters. \\[\\mu_0, \\psi_1, \\phi \\sim \\mathrm{Normal}(0, 1)\\] As explained in Chapter 1 (1.5), we also place priors on the total phenotypic variance of the SRN intercepts and slopes, as well as SRN heritability parameters that are used to derive the additive genetic and permanent environmental variance. \\[\\mathrm{sd}([\\boldsymbol{\\mu},\\boldsymbol{\\mu&#39;}]), \\mathrm{sd}([\\boldsymbol{\\psi},\\boldsymbol{\\psi&#39;}])\\sim \\mathrm{Half-Cauchy}(0,1)\\] \\[h_{\\mu}^{2}, h_{\\psi}^{2} \\sim \\mathrm{Beta}(1.2,1.2) \\] where \\[\\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{A}}) = h_{\\mu}^{2} \\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{ }}) \\\\ \\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{E}}) = (1-h_{\\mu}^{2})\\mathrm{Var}(\\boldsymbol{\\mu_\\mathrm{ }})\\] \\[\\mathrm{Var}(\\boldsymbol{\\psi_\\mathrm{A}}) = h_{\\psi}^{2} \\mathrm{Var}(\\boldsymbol{\\psi_\\mathrm{ }}) \\\\ \\mathrm{Var}(\\boldsymbol{\\psi_\\mathrm{E}}) = (1-h_{\\psi}^{2})\\mathrm{Var}(\\boldsymbol{\\psi_\\mathrm{ }})\\] Priors can also be placed on the genetic and permanent environmental correlations \\[\\boldsymbol{\\mathrm{G}_{cor}},\\boldsymbol{\\mathrm{E}_{cor}} \\sim \\mathrm{LKJ}(2)\\] The same approach is used for decomposing the residual covariance matrix \\(\\boldsymbol{\\Sigma}\\). \\[\\mathrm{sd}([\\boldsymbol{\\epsilon},\\boldsymbol{\\epsilon&#39;}]) \\sim \\mathrm{Half-Cauchy}(0,1)\\] \\[\\boldsymbol{\\mathrm{\\Sigma}_{cor}} \\sim \\mathrm{LKJ}(2)\\] 2.3 Simulate data 2.3.1 SRN parameters Here we rely on the custom pedfun() function introduced in Chapter 1 to generate an \\(\\boldsymbol{\\mathrm{A}}\\) matrix. We begin by setting the population parameters and simulating the SRN intercepts and slopes of males and females, assuming as stated above that their SRN parameters are characterized by equivalent covariance matrices. library(mvtnorm) #population properties I=300 #total individuals for simulation popmin=400 popmax=600 ngenerations = 10 nids&lt;-sample(popmin:popmax, ngenerations, replace=TRUE) #N / generation epm = sample(seq(0.15, 0.25,by=0.05),1) #extra-pair mating nonb = sample(seq(0.4,0.6,by=0.05),1) #proportion of non-breeding / generation #relatedness matrix A_mat &lt;- pedfun(popmin=popmin, popmax=popmax, ngenerations=ngenerations, epm=epm, nonb=nonb, nids=nids, I=I, missing=FALSE) ##################################################################### #Parameter values ##################################################################### alpha_0 = 0 #global intercept psi_1 = -0.5 #population interaction coefficient phi = 0.5 #residual feedback coefficient (epsilon_j ~ epsilon_t-1k) SD_intercept = 0.3 #standard deviation of SRN intercepts SD_slope = 0.3 #SD of SRN slopes r_alpha = 0.3 #assortment coefficient (expressed as correlation) r_G = 0.3 #genetic correlation of random intercepts and slopes r_E = 0.3 #environmental correlation r_R = -0.3 #residual effect correlation (epsilon_tj = epsilon_tk) V_G = 0.3 #genetic variance of REs V_E = 0.3 #genetic variance of REs res_V = 1 #Random effect correlations G_cor &lt;- matrix(c(1,r_G,r_G,1), nrow=2, ncol=2) #mu_A, beta_A G_sd &lt;- c(sqrt(V_G),sqrt(V_G)) #G effect sds G_cov &lt;- diag(G_sd) %*% G_cor %*% diag(G_sd) E_cor &lt;- matrix(c(1,r_E,r_E,1), nrow=2, ncol=2) #mu_E, beta_E E_sd &lt;- c(sqrt(V_E),sqrt(V_E)) #E effect sds E_cov &lt;- diag(E_sd) %*% E_cor %*% diag(E_sd) #matrices G_block &lt;- G_cov %x% A_mat E_block &lt;- E_cov %x% diag(1,I) #generate correlated REs Gvalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=G_block) G_val = data.frame(matrix(Gvalues, nrow=I, ncol=2)) cor(G_val) ## X1 X2 ## X1 1.0000000 0.3501241 ## X2 0.3501241 1.0000000 Evalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=E_block) E_val = data.frame(matrix(Evalues, nrow=I, ncol=2)) cor(E_val) ## X1 X2 ## X1 1.0000000 0.3753003 ## X2 0.3753003 1.0000000 #combine temporary object for all SRN parameters #use shorthand mu = 0, psi = 1 P = cbind(G_val,E_val) colnames(P) = c(&quot;A0&quot;, &quot;A1&quot;, &quot;E0&quot;, &quot;E1&quot;) #individual phenotypic REs #use shorthand mu = 0, psi = 1 P$P0 = P$A0 + P$E0 P$P1 = P$A1 + P$E1 #add ID P$ID = seq(1:I) 2.3.2 Assortment We can now split the generated values into male and female values, assuming both sexes are evenly sampled so that \\(N_M = N_F=N/2\\). As is explained in Appendix S1 of Martin and Jaeggi (2021), we can then use a simple sorting procedure to assortment individuals on a single SRN parameter. In this case, we use the SRN intercepts \\(\\boldsymbol{\\mu}\\). A more general approach would be use to an additional social matrix \\(\\boldsymbol{\\mathrm{S}}\\) to add to the relatedness matrix \\(\\boldsymbol{\\mathrm{A}}\\) prior to scaling the additive genetic values. library(MASS) #split male and female values + add arbitrary ID #use P0=mu and P1=psi for shorthand sort.m = data.frame(P0_m = P$P0[1:(I/2)], ID_m = 1:(I/2) ) sort.f = data.frame(P0_f = P$P0[(I/2+1):I], ID_f = (I/2+1):I) #sort by SRN intercept value sort.m&lt;-sort.m[order(sort.m[,&quot;P0_m&quot;]),] sort.f&lt;-sort.f[order(sort.f[,&quot;P0_f&quot;]),] #generate random dataset with desired rank-order correlation temp_mat &lt;- matrix(r_alpha, ncol = 2, nrow = 2) #cor of male and female values diag(temp_mat) &lt;- 1 #cor matrix temp_data1&lt;-mvrnorm(n = I/2, mu = c(0, 0), Sigma = temp_mat, empirical=TRUE) #ranks of random data rm &lt;- rank(temp_data1[ , 1], ties.method = &quot;first&quot;) rf &lt;- rank(temp_data1[ , 2], ties.method = &quot;first&quot;) #induce cor through rank-ordering of RN vectors cor(sort.m$P0_m[rm], sort.f$P0_f[rf]) ## [1] 0.3052259 #sort partner ids into dataframe (order on male ID) partner.id = data.frame(ID_m = sort.m$ID_m[rm], ID_f = sort.f$ID_f[rf]) partner.id = partner.id[order(partner.id[,&quot;ID_m&quot;]),] With the assorted ranks in partner.id, we can then structure the dataframe appropriately to match male and female partners with the desired correlation in SRN intercepts. #put all dyads together partner.id$dyadn = seq(1:nrow(partner.id)) #add values back to dataframe (male and joint) partner.id$P0m &lt;- P$P0[match(partner.id$ID_m,P$ID)] partner.id$P0f &lt;- P$P0[match(partner.id$ID_f,P$ID)] partner.id$P1m &lt;- P$P1[match(partner.id$ID_m,P$ID)] partner.id$P1f &lt;- P$P1[match(partner.id$ID_f,P$ID)] partner.id$A0m &lt;- P$A0[match(partner.id$ID_m,P$ID)] partner.id$A0f &lt;- P$A0[match(partner.id$ID_f,P$ID)] partner.id$A1m &lt;- P$A1[match(partner.id$ID_m,P$ID)] partner.id$A1f &lt;- P$A1[match(partner.id$ID_f,P$ID)] partner.id$E0m &lt;- P$E0[match(partner.id$ID_m,P$ID)] partner.id$E0f &lt;- P$E0[match(partner.id$ID_f,P$ID)] partner.id$E1m &lt;- P$E1[match(partner.id$ID_m,P$ID)] partner.id$E1f &lt;- P$E1[match(partner.id$ID_f,P$ID)] #check correlation again cor(partner.id$P0m, partner.id$P0f) ## [1] 0.3052259 #check data structure head(partner.id) ## ID_m ID_f dyadn P0m P0f P1m P1f A0m A0f A1m A1f E0m E0f E1m E1f ## 83 1 158 1 -0.60447737 0.3002294 0.1381750 0.9197807 0.08242542 0.42929926 0.07483432 0.7503359 -0.6869028 -0.1290699 0.06334066 0.1694448 ## 128 2 234 2 0.44516978 -0.1251509 0.4758293 -0.8039042 0.14478761 -1.23563991 -0.09839661 -0.4920228 0.3003822 1.1104890 0.57422587 -0.3118813 ## 79 3 272 3 0.29663393 -1.3752583 -0.1079828 -0.9338810 0.46308917 -0.99745270 0.67619892 -0.8060799 -0.1664552 -0.3778056 -0.78418171 -0.1278011 ## 130 4 215 4 0.65868965 2.0620621 0.7574922 1.1235457 0.02848557 0.78063584 0.58771664 -0.2054451 0.6302041 1.2814263 0.16977559 1.3289908 ## 119 5 206 5 0.95374875 0.2837430 1.2076925 0.9229270 1.22823523 0.48233291 1.06921250 0.3376829 -0.2744865 -0.1985899 0.13847997 0.5852441 ## 62 6 190 6 0.07910526 1.0907414 -0.4165885 0.3179899 -0.04883328 0.07890664 -0.58289345 -0.5501955 0.1279385 1.0118348 0.16630497 0.8681854 2.3.3 Repeated measurements within the partner For simplicity we consider a case with measurements of focal individuals and social partners taken over two discrete sampling periods, so that the time index \\(t= \\left \\{ 1,2 \\right \\}\\). We begin by expanding the dataframe for two measurements. #number of dyads ndyad = nrow(partner.id) #expand for repeated measures partner.id$rep &lt;- 2 #two repeated measurements pair_df &lt;- partner.id[rep(row.names(partner.id), partner.id$rep),] We can first calculate the partner residuals for each observation, which will be used in the residual feedback component of the autoregressive moving average (ARMA) function specified in the next step. #correlated residuals between male and females R_cor &lt;- matrix(c(1,r_R,r_R,1), nrow=2, ncol=2) res_sd &lt;- sqrt(res_V) R_cov &lt;- diag(c(res_sd,res_sd)) %*% R_cor %*% diag(c(res_sd,res_sd)) res_ind&lt;-data.frame(rmvnorm(nrow(pair_df), c(0,0), R_cov)) pair_df$resAGm = res_ind$X1 pair_df$resAGf = res_ind$X2 We can now specify our ARMA process across measurement time 1 and 2 for the latent SRN trait values for males \\(\\boldsymbol{\\eta}\\) and females \\(\\boldsymbol{\\eta&#39;}\\), as well as the SRN measurement errors \\(\\boldsymbol{\\xi}\\) and \\(\\boldsymbol{\\xi&#39;}\\). ##################################################################### #Simulate responses over t = {1,2} per partner ##################################################################### #add interaction number pair_df$turn = rep(c(1,2),ndyad) #individual prediction at t = 1 #males #eta_j{t=1} = mu_j + (psi + psi_j)*mu_k pair_df[pair_df$turn==1,&quot;eta_m&quot;] = pair_df[pair_df$turn==1,&quot;P0m&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;P1m&quot;])*(pair_df[pair_df$turn==1,&quot;P0f&quot;]) #females #eta_k{t=1} = mu_k +(psi + psi_k)*mu_j pair_df[pair_df$turn==1,&quot;eta_f&quot;] = pair_df[pair_df$turn==1,&quot;P0f&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;P1f&quot;])*(pair_df[pair_df$turn==1,&quot;P0m&quot;]) #individual prediction at t = 2 #males #eta_j{t=2} = mu_j + (psi + psi_j)*(eta_k{t=1}) pair_df[pair_df$turn==2,&quot;eta_m&quot;] = pair_df[pair_df$turn==2,&quot;P0m&quot;] + (psi_1 + pair_df[pair_df$turn==2,&quot;P1m&quot;])*(pair_df[pair_df$turn==1,&quot;eta_f&quot;]) #females #eta_k{t=2} = mu_k + (psi + psi_k)*(eta_j{t=1}) pair_df[pair_df$turn==2,&quot;eta_f&quot;] = pair_df[pair_df$turn==2,&quot;P0f&quot;] + (psi_1 + pair_df[pair_df$turn==2,&quot;P1f&quot;])*(pair_df[pair_df$turn==1,&quot;eta_m&quot;]) #add intercept and residuals (other fixed effects could be added here as well) pair_df$AG_m = alpha_0 + pair_df$eta_m + pair_df$resAGm pair_df$AG_f = alpha_0 + pair_df$eta_f + pair_df$resAGf #add residual feedback process pair_df[pair_df$turn==2,&quot;AG_m&quot;] = pair_df[pair_df$turn==2,&quot;AG_m&quot;] + phi * pair_df[pair_df$turn==1,&quot;resAGf&quot;] pair_df[pair_df$turn==2,&quot;AG_f&quot;] = pair_df[pair_df$turn==2,&quot;AG_f&quot;] + phi * pair_df[pair_df$turn==1,&quot;resAGm&quot;] By adding together the SRN and residual feedback processes, we finally get the measured aggression trait values for males AG_m and females AG_f. Note that, because of the feedback process, it is more straightforward to specify these Gaussian responses by adding together their constitutive components, than by trying to sample responses directly from a distribution, e.g. such as \\(z_{jt} \\sim \\mathrm{MVNormal}(\\eta_{jt}+\\xi_{jt}, \\boldsymbol{\\Sigma})\\). We will similarly modify our basic animal model code in Stan when accounting for this ARMA process. To aid in structuring our Stan model, we can also create some additional values and indices for males and females, which can be used to pull the appropriate focal and partner trait values from the vectors SRN parameters. The data can then be collected together in a list for Stan. #individual indices Im = I/2 #number of males If = I/2 #number of females N_sex = (I/2)*2 #total observations per sex idm&lt;-pair_df$ID_m #male ID idf&lt;-pair_df$ID_f #female ID idf&lt;-idf - Im #within female vector #data prep for Stan stan_data &lt;- list(N_sex = N_sex, I = I, Im=Im, If = If, idm = idm, idf = idf, AG_m = pair_df$AG_m, AG_f = pair_df$AG_f, time = pair_df$turn, A = A_mat) 2.4 Coding the model Were now prepared to code up our formal model in Stan. The basic structure builds on the animal model presented in Chapter 1 ((1.5)) with some small changes in labels, so we only direct attention toward new features of the social animal model code. Firstly, we need to declare the new data were passing into the model data { //indices and scalars used for model specification int&lt;lower=1&gt; N_sex; //total aggression observations per sex (I/2 * 2 repeated measures) int&lt;lower=0&gt; I; //total individuals (M + F) int&lt;lower=0&gt; Im; //number of males int&lt;lower=0&gt; If; //number of females int&lt;lower=1&gt; idm[N_sex]; //index of male AG observations (of length N_sex) int&lt;lower=1&gt; idf[N_sex]; //index of female AG observations //empirical data matrix[I,I] A; //relatedness matrix real AG_m[N_sex]; //male aggression measurements real AG_f[N_sex]; //female aggression measurements real time[N_sex]; //time index (1,2 per individual) } transformed data{ matrix[I,I] LA = cholesky_decompose(A); //lower-triangle A matrix } Then we adjust the parameters and transformed parameters. For the parameters, all we need to do is change the population regression coefficient \\(\\beta_1\\) to the population interaction coefficient \\(\\psi_1\\) and add a new residual feedback coefficient \\(\\phi\\). To facilitate identification, we set \\(-1 &lt;\\phi &lt; 1\\). Note that for efficiency weve dropped the previous cor labels from the lower Cholesky correlation matrices. The transformed parameters can otherwise be left as they previously were. Note that separate (co)variances could instead be estimated here for males and females here by declaring duplicate objects with sex-specific labels (and appropriately scaled relatedness matrices). parameters { //population effects real alpha_0; //aggression global intercept real psi_1; //expected interaction coefficient real&lt;lower=-1,upper=1&gt; phi; //(-1,1) ensures unique solution //random effects (standard deviations) vector&lt;lower=0, upper = 1&gt;[2] sd_P; //phenotypic SRN mu &amp; psi SDs vector&lt;lower=0, upper = 1&gt;[2] sd_R; //male &amp; female residual SDs cholesky_factor_corr[2] LG; //genetic SRN correlations cholesky_factor_corr[2] LE; //permanent environmental SRN correlations cholesky_factor_corr[2] LR; //sex-specific residual correlations matrix[I,2] std_devG; //individual-level unscaled G SRN deviations matrix[I,2] std_devE; //individual-level unscaled E SRN deviations //SRN heritability parmameters, i.e. Var(G_RN) / Var(P_RN) //see supplementary appendix SI for further explanation of this parameter vector&lt;lower=0,upper=1&gt;[2] SRN_h2; } transformed parameters { vector&lt;lower=0&gt;[2] sd_G; //SDs of G effects (derived from sd_P) vector&lt;lower=0&gt;[2] sd_E; //SDs of E effects (derived from sd_P) matrix[I,2] SRN_P; //scaled P SRN parameter deviations matrix[I,2] SRN_G; //scaled G SRN parameter deviations matrix[I,2] SRN_E; //scaled E SRN parameter deviations //standard deviations of genetic effects //simplified from sqrt ( total RN phenotype variance * h2 ) sd_G[1] = sd_P[1] * sqrt(SRN_h2[1]); //genetic SD for RN intercepts sd_G[2] = sd_P[2] * sqrt(SRN_h2[2]); //genetic SD for RN slopes //standard deviations of environmental effects (total phenotype SD * proportion environment SD) sd_E[1] = sd_P[1] * sqrt(1 - SRN_h2[1]); //environment SD for RN intercepts sd_E[2] = sd_P[2] * sqrt(1 - SRN_h2[2]); //environment SD for RN slopes //matrix normal parameterization of Kronecker product between G and A SRN_G = LA * std_devG * diag_pre_multiply(sd_G, LG)&#39; ; //non-centered parameterization of permanent environmental effects SRN_E = std_devE * diag_pre_multiply(sd_E, LE)&#39;; //phenotypic RN effects (P = G + E); here G = additive genetic effects SRN_P = SRN_G + SRN_E; } We could separate the male and female SRN parameters in the transformed parameters block and save them along with the other estimated parameters, but this would be redundant. Instead, we aid coding by creating temporary sex-specific vectors in the model block. We also create temporary vectors for defining the time-specific SRN trait values and residuals. As noted above, we declare the residual vectors explicitly in the model, rather than using a standard generative distribution, because we need to flexibly specify the time-lagged associations among focal and social partner residuals. model{ //separate male and female vectors for efficiency matrix[Im,2] SRN_Pm = SRN_P[1:Im]; //male SRN phenotypic deviations matrix[If,2] SRN_Pf = SRN_P[(Im+1):I]; //female SRN phenotypic deviations //separate SRN intercepts and slopes (phenotypic deviations) vector[Im] mu_m = col(SRN_Pm,1); //SRN intercepts vector[If] mu_f = col(SRN_Pf,1); vector[Im] psi_m = col(SRN_Pm,2); //SRN slopes vector[If] psi_f = col(SRN_Pf,2); //initialize vectors for constructing individual-centered linear predictors vector[N_sex] eta_m; //male SRN trait value vector[N_sex] eta_f; //female SRN trait value vector[N_sex] linpred_m; //total expected value for male responses vector[N_sex] linpred_f; //total expected value for female responses vector[N_sex] epsilon_m; //residual for male responses vector[N_sex] epsilon_f; //residual for female responses //... We can now use a conditional statement in Stan to first calculate the SRN trait values \\(\\boldsymbol{\\eta}\\) and \\(\\boldsymbol{\\eta}&#39;\\). Here we use the previously created indices of IDs and time stamps to ensure that each observation is appropriately matched between focal individual and social partners. //Male and female aggression response model for (n in 1:N_sex) { //SRN trait values //assumes that n = 1 in the context of an ongoing social interaction //if n = 1 prior to social context, then specify eta[t=1] = mu_j instead if (time[n]==1) { //male eta[t=1] = mu_j + (psi + psi_j)*(mu_k) eta_m[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(mu_f[idf[n]]) ; //female eta[t=1] = mu_k + (psi + psi_k)*(mu_j) eta_f[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(mu_m[idm[n]]); } else { //male eta[t=2] = mu_j + (psi + psi_j)*(eta_k[t=1]) eta_m[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(eta_Wf[n-1]); //female eta[t=2] = mu_k + (psi + psi_k)*(eta_j[t=1]) eta_f[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(eta_Wm[n-1]); } //... The global intercept \\(\\mu_0\\) and any other fixed or random effects of interest can then be added along with the SRN trait value subject to feedback. //add global intercept and between-individual parameters to linear predictor //other fixed effects can also be added here linpred_m[n] = alpha_0 + eta_m[n]; linpred_f[n] = alpha_0 + eta_f[n]; //... With these values in place, the initial residual value for each male and female partner at time \\(t=1\\) can be calculated and subsequently used to estimate residual feedback at \\(t=2\\), as well as to specify any remaining correlation between the focal and partner residual trait values. The parameter priors are also placed below to finish off the model block. //residual trait values if(time[n]==1) { epsilon_m [n] = AG_m[n] - linpred_m[n]; epsilon_f [n] = AG_f[n] - linpred_f[n]; } else { linpred_m[n] = linpred_m[n] + phi * epsilon_f[n-1]; epsilon_m[n] = AG_m[n] - linpred_m[n]; linpred_f[n] = linpred_f[n] + phi * epsilon_m[n-1]; epsilon_f[n] = AG_f[n] - linpred_f[n]; } //correlated residuals between partners [epsilon_m[n],epsilon_f[n]]&#39; ~ multi_normal_cholesky([0,0], diag_pre_multiply(sd_R, LR)); } //end of for (n in 1:N_sex) //model priors //fixed effects alpha_0 ~ std_normal(); psi_1 ~ std_normal(); phi ~ std_normal(); //random effects to_vector(sd_P) ~ cauchy(0,1); to_vector(sd_R) ~ cauchy(0,1); LG ~ lkj_corr_cholesky(2); LE ~ lkj_corr_cholesky(2); LR ~ lkj_corr_cholesky(2); to_vector(std_devG) ~ std_normal(); to_vector(std_devE) ~ std_normal(); //reaction norm heritability to_vector(SRN_h2) ~ beta(1.2,1.2); } Things can be finished off by declaring the relevant generated quantities. generated quantities{ //cor and cov matrices of SRN parameters and residuals matrix[2,2] Gcor = LG * LG&#39;; //G SRN correlation matric matrix[2,2] Ecor = LE * LE&#39;; //E SRN correlation matric matrix[2,2] Rcor = LR * LR&#39;; //residual correlation matrix matrix[2,2] Rcov = diag_matrix(sd_R)*Rcor*diag_matrix(sd_R); //residual covariance matrix[2,2] Gcov = diag_matrix(sd_G)*Gcor*diag_matrix(sd_G); //G SRN covariance matrix[2,2] Ecov = diag_matrix(sd_E)*Ecor*diag_matrix(sd_E); //E SRN covariance matrix[2,2] Pcov = Gcov + Ecov; //P SRN covariance matrix[2,2] Pcor = inverse(diag_matrix(sd_P))*Pcov*inverse(diag_matrix(sd_P)); //P SRN correlation //variances vector&lt;lower=0&gt;[2] V_P = sd_P .* sd_P; vector&lt;lower=0&gt;[2] V_G = sd_G .* sd_G; vector&lt;lower=0&gt;[2] V_E = sd_E .* sd_E; vector&lt;lower=0&gt;[2] V_R = sd_R .* sd_R; } Putting everything together now. write(&quot; data { //indices and scalars used for model specification int&lt;lower=1&gt; N_sex; //total aggression observations per sex (I/2 * 2 repeated measures) int&lt;lower=0&gt; I; //total individuals (M + F) int&lt;lower=0&gt; Im; //number of males int&lt;lower=0&gt; If; //number of females int&lt;lower=1&gt; idm[N_sex]; //index of male AG observations (of length N_sex) int&lt;lower=1&gt; idf[N_sex]; //index of female AG observations //empirical data matrix[I,I] A; //relatedness matrix real AG_m[N_sex]; //male aggression measurements real AG_f[N_sex]; //female aggression measurements real time[N_sex]; //time index (1,2 per individual) } transformed data{ matrix[I,I] LA = cholesky_decompose(A); //lower-triangle A matrix } parameters { //population effects real alpha_0; //aggression global intercept real psi_1; //expected interaction coefficient real&lt;lower=-1,upper=1&gt; phi; //(-1,1) ensures unique solution //random effects (standard deviations) vector&lt;lower=0, upper = 1&gt;[2] sd_P; //phenotypic SRN mu &amp; psi SDs vector&lt;lower=0, upper = 1&gt;[2] sd_R; //male &amp; female residual SDs cholesky_factor_corr[2] LG; //genetic SRN correlations cholesky_factor_corr[2] LE; //permanent environmental SRN correlations cholesky_factor_corr[2] LR; //sex-specific residual correlations matrix[I,2] std_devG; //individual-level unscaled G SRN deviations matrix[I,2] std_devE; //individual-level unscaled E SRN deviations //SRN heritability parmameters, i.e. Var(G_RN) / Var(P_RN) //see supplementary appendix SI for further explanation of this parameter vector&lt;lower=0,upper=1&gt;[2] SRN_h2; } transformed parameters { vector&lt;lower=0&gt;[2] sd_G; //SDs of G effects (derived from sd_P) vector&lt;lower=0&gt;[2] sd_E; //SDs of E effects (derived from sd_P) matrix[I,2] SRN_P; //scaled P SRN parameter deviations matrix[I,2] SRN_G; //scaled G SRN parameter deviations matrix[I,2] SRN_E; //scaled E SRN parameter deviations //standard deviations of genetic effects //simplified from sqrt ( total RN phenotype variance * h2 ) sd_G[1] = sd_P[1] * sqrt(SRN_h2[1]); //genetic SD for RN intercepts sd_G[2] = sd_P[2] * sqrt(SRN_h2[2]); //genetic SD for RN slopes //standard deviations of environmental effects (total phenotype SD * proportion environment SD) sd_E[1] = sd_P[1] * sqrt(1 - SRN_h2[1]); //environment SD for RN intercepts sd_E[2] = sd_P[2] * sqrt(1 - SRN_h2[2]); //environment SD for RN slopes //matrix normal parameterization of Kronecker product between G and A SRN_G = LA * std_devG * diag_pre_multiply(sd_G, LG)&#39; ; //non-centered parameterization of permanent environmental effects SRN_E = std_devE * diag_pre_multiply(sd_E, LE)&#39;; //phenotypic RN effects (P = G + E); here G = additive genetic effects SRN_P = SRN_G + SRN_E; } model{ //separate male and female vectors for efficiency matrix[Im,2] SRN_Pm = SRN_P[1:Im]; //male SRN phenotypic deviations matrix[If,2] SRN_Pf = SRN_P[(Im+1):I]; //female SRN phenotypic deviations //separate SRN intercepts and slopes (phenotypic deviations) vector[Im] mu_m = col(SRN_Pm,1); //SRN intercepts vector[If] mu_f = col(SRN_Pf,1); vector[Im] psi_m = col(SRN_Pm,2); //SRN slopes vector[If] psi_f = col(SRN_Pf,2); //initialize vectors for constructing individual-centered linear predictors vector[N_sex] eta_m; //male SRN trait value vector[N_sex] eta_f; //female SRN trait value vector[N_sex] linpred_m; //total expected value for male responses vector[N_sex] linpred_f; //total expected value for female responses vector[N_sex] epsilon_m; //residual for male responses vector[N_sex] epsilon_f; //residual for female responses //Male and female aggression response model for (n in 1:N_sex) { //SRN trait values //assumes that n = 1 in the context of an ongoing social interaction //if n = 1 prior to social context, then specify eta[t=1] = mu_j instead if (time[n]==1) { //male eta[t=1] = mu_j + (psi + psi_j)*(mu_k) eta_m[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(mu_f[idf[n]]) ; //female eta[t=1] = mu_k + (psi + psi_k)*(mu_j) eta_f[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(mu_m[idm[n]]); } else { //male eta[t=2] = mu_j + (psi + psi_j)*(eta_k[t=1]) eta_m[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(eta_f[n-1]); //female eta[t=2] = mu_k + (psi + psi_k)*(eta_j[t=1]) eta_f[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(eta_m[n-1]); } //add global intercept and between-individual parameters to linear predictor //other fixed effects can also be added here linpred_m[n] = alpha_0 + eta_m[n]; linpred_f[n] = alpha_0 + eta_f[n]; //residual trait values if(time[n]==1) { epsilon_m [n] = AG_m[n] - linpred_m[n]; epsilon_f [n] = AG_f[n] - linpred_f[n]; } else { linpred_m[n] = linpred_m[n] + phi * epsilon_f[n-1]; epsilon_m[n] = AG_m[n] - linpred_m[n]; linpred_f[n] = linpred_f[n] + phi * epsilon_m[n-1]; epsilon_f[n] = AG_f[n] - linpred_f[n]; } //correlated residuals between partners [epsilon_m[n],epsilon_f[n]]&#39; ~ multi_normal_cholesky([0,0], diag_pre_multiply(sd_R, LR)); } //model priors //fixed effects alpha_0 ~ std_normal(); psi_1 ~ std_normal(); phi ~ std_normal(); //random effects to_vector(sd_P) ~ cauchy(0,1); to_vector(sd_R) ~ cauchy(0,1); LG ~ lkj_corr_cholesky(2); LE ~ lkj_corr_cholesky(2); LR ~ lkj_corr_cholesky(2); to_vector(std_devG) ~ std_normal(); to_vector(std_devE) ~ std_normal(); //reaction norm heritability to_vector(SRN_h2) ~ beta(1.2,1.2); } generated quantities{ //cor and cov matrices of SRN parameters and residuals matrix[2,2] Gcor = LG * LG&#39;; //G SRN correlation matric matrix[2,2] Ecor = LE * LE&#39;; //E SRN correlation matric matrix[2,2] Rcor = LR * LR&#39;; //residual correlation matrix matrix[2,2] Rcov = diag_matrix(sd_R)*Rcor*diag_matrix(sd_R); //residual covariance matrix[2,2] Gcov = diag_matrix(sd_G)*Gcor*diag_matrix(sd_G); //G SRN covariance matrix[2,2] Ecov = diag_matrix(sd_E)*Ecor*diag_matrix(sd_E); //E SRN covariance matrix[2,2] Pcov = Gcov + Ecov; //P SRN covariance matrix[2,2] Pcor = inverse(diag_matrix(sd_P))*Pcov*inverse(diag_matrix(sd_P)); //P SRN correlation //variances vector&lt;lower=0&gt;[2] V_P = sd_P .* sd_P; vector&lt;lower=0&gt;[2] V_G = sd_G .* sd_G; vector&lt;lower=0&gt;[2] V_E = sd_E .* sd_E; vector&lt;lower=0&gt;[2] V_R = sd_R .* sd_R; }&quot;, &quot;sam3_1.stan&quot;) 2.5 Estimating the model We can now use our simulated random sample to estimate the full quantitative genetic SAM, and well run the the model for additional iterations to promote sufficient sampling of the individual-level parameters. A quick plot of the model results can give us an indication of whether the converse directions of the true SRN feedback (-0.5) and residual feedback (+0.5) processes are being appropriately estimated, as well the accuracy of recovering the total phenotypic variance (V = 0.6) and the genetic (r = 0.3), permanent environmental (r = 0.3), and residual (r = -0.3) correlations. library(rstan) sam_3.1 = stan_model(&quot;sam3_1.stan&quot;) ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): &#39;C:/rtools40/usr/mingw_/bin/g++&#39; not found stan_results3.1 &lt;- sampling(sam_3.1, data=stan_data, init = 0, warmup=1500, iter = 6000, chains=4, cores=4, control=list(adapt_delta=0.90) ) library(bayesplot) ## This is bayesplot version 1.8.0 ## - Online documentation and vignettes at mc-stan.org/bayesplot ## - bayesplot theme set to bayesplot::theme_default() ## * Does _not_ affect other ggplot2 plots ## * See ?bayesplot_theme_set for details on theme setting mcmc_areas(stan_results3.1, pars = c( &quot;psi_1&quot;, &quot;phi&quot;, &quot;V_P[1]&quot;, &quot;V_P[2]&quot;, &quot;Gcor[2,1]&quot;, &quot;Ecor[2,1]&quot;, &quot;Rcor[2,1]&quot;, &quot;Pcor[2,1]&quot; ), prob = 0.9 ) Despite the modest sample size for a quantitative genetic study, the SAM does a good job of detecting the opposing directional effects of SRN and residual feedback, as well as of residual and intrinsic trait value correlations. It is also noticeable that, despite the greater uncertainty in the genetic and permanent environmental correlations, the overall phenotypic variance is more precisely estimated. Thus, even when pedigrees are not sufficiently informative to confidently infer genetic effects, SAMs can still be used to estimate evolutionary parameters on phenotypes. 2.6 Failure to detect assortment We can attempt to estimate the assortment coefficient matrix, following Eq. 4 of Martin and Jaeggi (2021), with posterior distributions for the assortment coefficients for SRN intercepts and slopes given by \\[ \\beta_{\\bar{\\mu&#39;}\\mu} = \\Pr \\left ( \\frac{ \\mathrm{cov}( \\boldsymbol{\\mu}, \\boldsymbol{\\bar{\\mu}&#39;}) } {\\mathrm{var}(\\boldsymbol{\\mu})} \\mid \\boldsymbol{z}, \\boldsymbol{z&#39;}, \\boldsymbol{\\Theta} \\right ) \\] \\[ \\beta_{\\bar{\\psi&#39;}\\psi} = \\Pr \\left ( \\frac{ \\mathrm{cov}( \\boldsymbol{\\psi}, \\boldsymbol{\\bar{\\psi}&#39;}) } {\\mathrm{var}(\\boldsymbol{\\psi})} \\mid \\boldsymbol{z}, \\boldsymbol{z&#39;}, \\boldsymbol{\\Theta} \\right ) \\] The posterior of the full assortment coefficient matrix is \\[\\boldsymbol{ \\mathrm{B}_{\\alpha}} = \\Pr \\left ( \\begin{bmatrix} \\beta_{\\bar{\\mu&#39;}\\mu} &amp; \\beta_{\\bar{\\psi&#39;}\\mu} \\\\ \\beta_{\\bar{\\mu&#39;}\\psi} &amp; \\beta_{\\bar{\\psi&#39;}\\psi} \\end{bmatrix} \\mid \\boldsymbol{z}, \\boldsymbol{z&#39;}, \\boldsymbol{\\Theta} \\right ) \\] We can manually calculate this posterior matrix by post-processing the MCMC samples from our model. In this case, we only need to organize the male and female responses together and calculate the appropriate (co)variances, as each individual has a single partner. We therefore arbitrarily treat males as focal individuals, as the coefficient is equivalent in this case for both sexes. #extract posteriors post &lt;- rstan::extract(stan_results3.1) SRN_focal1 &lt;- post$SRN_P[,(1:Im),1] #male intercepts SRN_focal2 &lt;- post$SRN_P[,(1:Im),2] #male slopes SRN_partner1 &lt;- post$SRN_P[,(Im + unique(idf)),1] #female intercepts SRN_partner2 &lt;- post$SRN_P[,(Im + unique(idf)),2] #female intercepts #assortment matrix Beta_alpha = list() #generate matrices across each posterior sample for(j in 1:nrow(SRN_focal1)) { Beta_mat = matrix(NA,2,2) #mu&#39; ~ mu Beta_mat[1,1] = cov(SRN_focal1[j,], SRN_partner1[j,])/var(SRN_focal1[j,]) #mu&#39; ~ psi Beta_mat[2,1] = cov(SRN_focal2[j,], SRN_partner1[j,])/var(SRN_focal2[j,]) #psi&#39; ~ mu Beta_mat[1,2] = cov(SRN_focal1[j,], SRN_partner2[j,])/var(SRN_focal1[j,]) #psi&#39; ~ psi Beta_mat[2,2] = cov(SRN_focal2[j,], SRN_partner2[j,])/var(SRN_focal2[j,]) Beta_alpha[[j]] = Beta_mat } #extract beta_mu&#39;mu (assortment on RN intercepts) Beta_mu = unlist(lapply(Beta_alpha, function(x) x[1,1])) mean(Beta_mu) ## [1] 0.06894314 hist(Beta_mu) Perhaps surprisingly, we see that the model is not doing a good job of detecting the positive assortment between partners SRN intercepts (r = 0.3), instead centering the assortment coefficient on zero. Given our sample and effect size, it is unlikely that this would be caused by conservative model priors, and weve seen above that the model is doing a good job of estimating the other population parameters such as the interaction coefficient/SRN slope. Why would this be the case, given that this same approach is effective for estimating assortment in the between partner (??) and within-and-between partner SAMs (??)? In these latter models, variation across partners can be used to differentiate within-partner plasticity (SRN slopes) from between-partner assortment using within-individual centering. This leads to appropriate recovery of the assortment coefficient from the posterior SRN parameters, as individuals SRN parameters are accurately adjusted for between-individual heterogeneity in the social environment. However, in the within partner model, individuals only have a single social partner, and were unable to partition and adjust the random effect accordingly. For this reason, although the within partner model can provide accurate estimates of social plasticity and other population parameters, assortment is better estimated with multiple partner designs and within-individual centering. 2.7 Phenotypic model Note that a phenotypic version of this within partner model can easily be specified by simplifying the random effects to a single set of phenotypic SRN intercepts and slopes. write(&quot; data { //indices and scalars used for model specification int&lt;lower=1&gt; N_sex; //total aggression observations per sex (I/2 * 2 repeated measures) int&lt;lower=0&gt; I; //total individuals (M + F) int&lt;lower=0&gt; Im; //number of males int&lt;lower=0&gt; If; //number of females int&lt;lower=1&gt; idm[N_sex]; //index of male AG observations (of length N_sex) int&lt;lower=1&gt; idf[N_sex]; //index of female AG observations //empirical data real AG_m[N_sex]; //male aggression measurements real AG_f[N_sex]; //female aggression measurements real time[N_sex]; //time index (1,2 per individual) } parameters { //population effects real alpha_0; //aggression global intercept real psi_1; //expected interaction coefficient real&lt;lower=-1,upper=1&gt; phi; //(-1,1) ensures unique solution //random effects (standard deviations) vector&lt;lower=0, upper = 1&gt;[2] sd_P; //phenotypic SRN mu &amp; psi SDs vector&lt;lower=0, upper = 1&gt;[2] sd_R; //male &amp; female residual SDs cholesky_factor_corr[2] LP; //P SRN correlations cholesky_factor_corr[2] LR; //sex-specific residual correlations matrix[I,2] std_devP; //individual-level unscaled P SRN deviations } transformed parameters { matrix[I,2] SRN_P; //scaled P SRN parameter deviations //non-centered parameterization of permanent environmental effects SRN_P = std_devP * diag_pre_multiply(sd_P, LP)&#39;; } model{ //separate male and female vectors for efficiency matrix[Im,2] SRN_Pm = SRN_P[1:Im]; //male SRN phenotypic deviations matrix[If,2] SRN_Pf = SRN_P[(Im+1):I]; //female SRN phenotypic deviations //separate SRN intercepts and slopes (phenotypic deviations) vector[Im] mu_m = col(SRN_Pm,1); //SRN intercepts vector[If] mu_f = col(SRN_Pf,1); vector[Im] psi_m = col(SRN_Pm,2); //SRN slopes vector[If] psi_f = col(SRN_Pf,2); //initialize vectors for constructing individual-centered linear predictors vector[N_sex] eta_m; //male SRN trait value vector[N_sex] eta_f; //female SRN trait value vector[N_sex] linpred_m; //total expected value for male responses vector[N_sex] linpred_f; //total expected value for female responses vector[N_sex] epsilon_m; //residual for male responses vector[N_sex] epsilon_f; //residual for female responses //Male and female aggression response model for (n in 1:N_sex) { //SRN trait values //assumes that n = 1 in the context of an ongoing social interaction //if n = 1 prior to social context, then specify eta[t=1] = mu_j instead if (time[n]==1) { //male eta[t=1] = mu_j + (psi + psi_j)*(mu_k) eta_m[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(mu_f[idf[n]]) ; //female eta[t=1] = mu_k + (psi + psi_k)*(mu_j) eta_f[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(mu_m[idm[n]]); } else { //male eta[t=2] = mu_j + (psi + psi_j)*(eta_k[t=1]) eta_m[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(eta_f[n-1]); //female eta[t=2] = mu_k + (psi + psi_k)*(eta_j[t=1]) eta_f[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(eta_m[n-1]); } //add global intercept and between-individual parameters to linear predictor //other fixed effects can also be added here linpred_m[n] = alpha_0 + eta_m[n]; linpred_f[n] = alpha_0 + eta_f[n]; //residual trait values if(time[n]==1) { epsilon_m [n] = AG_m[n] - linpred_m[n]; epsilon_f [n] = AG_f[n] - linpred_f[n]; } else { linpred_m[n] = linpred_m[n] + phi * epsilon_f[n-1]; epsilon_m[n] = AG_m[n] - linpred_m[n]; linpred_f[n] = linpred_f[n] + phi * epsilon_m[n-1]; epsilon_f[n] = AG_f[n] - linpred_f[n]; } //correlated residuals between partners [epsilon_m[n],epsilon_f[n]]&#39; ~ multi_normal_cholesky([0,0], diag_pre_multiply(sd_R, LR)); } //model priors //fixed effects alpha_0 ~ std_normal(); psi_1 ~ std_normal(); phi ~ std_normal(); //random effects to_vector(sd_P) ~ cauchy(0,1); to_vector(sd_R) ~ cauchy(0,1); LP ~ lkj_corr_cholesky(2); LR ~ lkj_corr_cholesky(2); to_vector(std_devP) ~ std_normal(); } generated quantities{ //cor and cov matrices of SRN parameters and residuals matrix[2,2] Gcor = LP * LP&#39;; //P SRN correlation matric matrix[2,2] Rcor = LR * LR&#39;; //residual correlation matrix matrix[2,2] Rcov = diag_matrix(sd_R)*Rcor*diag_matrix(sd_R); //residual covariance matrix[2,2] Gcov = diag_matrix(sd_P)*Pcor*diag_matrix(sd_P); //P SRN covariance //variances vector&lt;lower=0&gt;[2] V_P = sd_P .* sd_P vector&lt;lower=0&gt;[2] V_R = sd_R .* sd_R; }&quot;, &quot;sam3_1P.stan&quot;) Resources "],["between-partner-sam.html", "3 Between partner SAM 3.1 Simulate data 3.2 Estimate the model 3.3 Estimating assortment 3.4 Phenotypic model", " 3 Between partner SAM Here we modify the within partner SAM for a between partner study design without repeated measures within partners. As explained in the main text [Martin and Jaeggi (2021); see Eq 3.2], this model can be considered as a simplification of the within partner model to remove feedback effects within partners (i.e. \\(t=1\\)). We therefore avoid repeating the detailed commentary on the formal and computational aspects of the model provided in the previous chapter. In contrast to within partner SAM, which fails to properly estimate assortment (2.6), a between partner SAM can be used to effectively partition assortment on SRN parameters using within-individual centering. The between partner SAM for a measurement \\(i\\) of aggression \\(z_{ijt=1}\\) in focal individual \\(j\\) during a single interaction period \\(t=1\\) is given by \\[z_{ijt=1} = \\mu_0 + \\eta_{ijt=1} + \\epsilon_{ijt=1}\\] \\[\\eta_{ijt=1} = \\mu_j + \\left( \\psi_1 + \\psi_j \\right)\\mu_k&#39;\\] \\[\\mu_j = \\mu_{\\mathrm{A}j} + \\mu_{\\mathrm{E}j}, \\quad \\psi_j = \\psi_{\\mathrm{A}j} + \\psi_{\\mathrm{E}j}\\] Note that the SRN measurement simply reduces to the residual trait value \\(\\epsilon_{ijt=1}\\) because there is no temporal information for partitioning residual feedback effects. When there individuals are non-randomly distributed across social partners (e.g. due to assortment), the SRN trait value should instead be decomposed into within \\(\\eta_{W}\\) and between \\(\\eta_{B}\\) partner components to adjust for unbalanced sampling \\[\\eta_{Wijt=1} = \\mu_j + \\left( \\psi_1 + \\psi_j \\right) \\left( \\mu_k&#39; - \\bar{\\mu}&#39;_K \\right)\\] \\[\\eta_{Bijt=1} =\\left( \\psi_1 + \\psi_j \\right) \\bar{\\mu}&#39;_K \\] where \\(\\bar{\\mu}&#39;_K\\) is the average SRN intercept of an individuals social partners. To appropriately adjust the intrinsic SRN parameters for the between-partner component, we need to introduce an additional regression parameter \\(\\beta_{B}\\) so that \\[z_{ijt=1} = \\mu_0 + \\eta_{Wijt=1} + \\beta_{B}\\eta_{Bijt=1} + \\epsilon_{ijt=1}\\] The equivalent specification can be given for the social partners aggression measure \\(z_{ikt=1}&#39;\\) \\[z_{ikt=1}&#39; = \\mu_0 + \\eta_{Wikt=1}&#39; + \\beta_{B}\\eta_{Bikt=1}&#39; + \\epsilon_{ikt=1}&#39;\\] \\[\\eta_{Wikt=1}&#39; = \\mu_k&#39; + \\left( \\psi_1 + \\psi_k&#39; \\right) \\left( \\mu_j - \\bar{\\mu}_J \\right) \\] \\[\\eta_{Bikt=1}&#39; = \\mu_k&#39; + \\left( \\psi_1 + \\psi_k&#39; \\right) \\bar{\\mu}_J\\] \\[\\mu_k&#39; = \\mu_{\\mathrm{A}k}&#39; + \\mu_{\\mathrm{E}j}&#39;, \\quad \\psi_k&#39; = \\psi_{\\mathrm{A}k}&#39; + \\psi_{\\mathrm{E}k}&#39;\\] The random effects are assumed to be well-described by multivariate normal distributions. \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\mu&#39;_{\\mathrm{A}}},\\boldsymbol{\\psi_{\\mathrm{A}}},\\boldsymbol{\\psi}&#39;_{\\mathrm{A}} \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}} ) \\] \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{E}}}, \\boldsymbol{\\mu&#39;_{\\mathrm{E}}},\\boldsymbol{\\psi_{\\mathrm{E}}},\\boldsymbol{\\psi}&#39;_{\\mathrm{E}} \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{E}} \\otimes \\boldsymbol{\\mathrm{I}} ) \\] \\[\\begin{bmatrix} \\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon}&#39; \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{\\Sigma}} ) \\] We also assume that the social reaction norm (SRN) intercept and slope (co)variances are equivalent for focal (\\(\\boldsymbol{\\mu},\\boldsymbol{\\psi}\\)) and social partners (\\(\\boldsymbol{\\mu}&#39;,\\boldsymbol{\\psi}&#39;\\)). The \\(\\boldsymbol{G}\\) matrix can therefore be reduced to a 2x2 matrix for all individuals in the population \\[\\boldsymbol{\\mathrm{G}}= \\begin{bmatrix} \\mathrm{var([\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;])} &amp; \\mathrm{cov([\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;],[\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;])} \\\\ \\mathrm{cov([\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;],[\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;])} &amp; \\mathrm{var([\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;])} \\end{bmatrix}\\] The residual matrix \\(\\boldsymbol{\\Sigma}\\) estimates the association among focal and social partners residuals. \\[\\boldsymbol{\\Sigma}= \\begin{bmatrix} \\mathrm{var(\\boldsymbol{\\epsilon})} &amp; \\mathrm{cov}(\\boldsymbol{\\epsilon},\\boldsymbol{\\epsilon}&#39;) \\\\ \\mathrm{cov}(\\boldsymbol{\\epsilon}&#39;,\\boldsymbol{\\epsilon}) &amp; \\mathrm{var(\\boldsymbol{\\epsilon&#39;})} \\end{bmatrix}\\] This model is, therefore, appropriate for situations where the distinction between focal and partner is semi-arbitrary, e.g. when measuring within-sex interactions or when males and females exhibit similar patterns of phenotypic variation. In this case, we make the latter assumption for simplicity. To account for differences between the responses of focal individuals and social partners, the model can simply be extended with additional parameters, e.g. specifying separate \\(G_M\\) and \\(G_F\\) matrices for males and female respective genetic (co)variances and so on. 3.1 Simulate data We now need to simulate interactions across multiple partners. Fortunately, we follow the same basic approach as the previous chapter, including use of the the custom pedfun() function introduced in Ch. 1.5 for generating a genetic VCV. For heuristic purposes, we can consider our simulation as capturing interactions and assortment of each individual with four lifetime partners. library(mvtnorm) #common settings I_partner = 4 #partners/individual I_obs = 1 #observations/individual/seasonal partner I_sample = I_partner*I_obs #samples/individual #population properties I = 300 #total individuals for simulation popmin=400 popmax=600 ngenerations = 10 nids&lt;-sample(popmin:popmax, ngenerations, replace=TRUE) #N / generation epm = sample(seq(0.15, 0.25,by=0.05),1) #extra-pair mating nonb = sample(seq(0.4,0.6,by=0.05),1) #proportion of non-breeding / generation #relatedness matrix A_mat &lt;- pedfun(popmin=popmin, popmax=popmax, ngenerations=ngenerations, epm=epm, nonb=nonb, nids=nids, I=I, missing=FALSE) ##################################################################### #Parameter values ##################################################################### alpha_0 = 0 #global intercept psi_1 = -0.5 #population interaction coefficient phi = 0.5 #residual feedback coefficient (epsilon_j ~ epsilon_t-1k) SD_intercept = 0.3 #standard deviation of SRN intercepts SD_slope = 0.3 #SD of SRN slopes r_alpha = 0.3 #assortment coefficient (expressed as correlation) r_G = 0.3 #genetic correlation of random intercepts and slopes r_E = 0.3 #environmental correlation r_R = -0.3 #residual effect correlation (epsilon_tj = epsilon_tk) V_G = 0.3 #genetic variance of REs V_E = 0.3 #genetic variance of REs res_V = 1 #Random effect correlations G_cor &lt;- matrix(c(1,r_G,r_G,1), nrow=2, ncol=2) #mu_A, beta_A G_sd &lt;- c(sqrt(V_G),sqrt(V_G)) #G effect sds G_cov &lt;- diag(G_sd) %*% G_cor %*% diag(G_sd) E_cor &lt;- matrix(c(1,r_E,r_E,1), nrow=2, ncol=2) #mu_E, beta_E E_sd &lt;- c(sqrt(V_E),sqrt(V_E)) #E effect sds E_cov &lt;- diag(E_sd) %*% E_cor %*% diag(E_sd) #matrices G_block &lt;- G_cov %x% A_mat E_block &lt;- E_cov %x% diag(1,I) #generate correlated REs Gvalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=G_block) G_val = data.frame(matrix(Gvalues, nrow=I, ncol=2)) cor(G_val) ## X1 X2 ## X1 1.0000000 0.3884289 ## X2 0.3884289 1.0000000 Evalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=E_block) E_val = data.frame(matrix(Evalues, nrow=I, ncol=2)) cor(E_val) ## X1 X2 ## X1 1.0000000 0.2761548 ## X2 0.2761548 1.0000000 #combine temporary object for all SRN parameters #use shorthand mu = 0, psi = 1 P = cbind(G_val,E_val) colnames(P) = c(&quot;A0&quot;, &quot;A1&quot;, &quot;E0&quot;, &quot;E1&quot;) #individual phenotypic REs #use shorthand mu = 0, psi = 1 P$P0 = P$A0 + P$E0 P$P1 = P$A1 + P$E1 #add ID P$ID = seq(1:I) The assortment procedure is fundamentally the same but now considers multiple partners. library(dplyr) library(MASS) pairs = list() for (j in 1:I_partner){ #male RN intercept (x I_partner for multiple lifetime partners) sort.m &lt;- data.frame(P0_m = P$P0[1:(I/2)], ID_m = (1:(I/2)) ) sort.m&lt;-sort.m[order(sort.m[,&quot;P0_m&quot;]),] #female phenotypic RN slopes sort.f &lt;- data.frame(P0_f = P$P0[(I/2 + 1):I], ID_f = ((I/2+1):I) ) sort.f&lt;-sort.f[order(sort.f[,&quot;P0_f&quot;]),] #generate random dataset with desired rank-order correlation temp_mat &lt;- matrix(r_alpha, ncol = 2, nrow = 2) #cor of male and female values diag(temp_mat) &lt;- 1 #cor matrix #sim values temp_data1&lt;- mvrnorm(n = I/2, mu = c(0, 0), Sigma = temp_mat, empirical=TRUE) #ranks of random data rm &lt;- rank(temp_data1[ , 1], ties.method = &quot;first&quot;) rf &lt;- rank(temp_data1[ , 2], ties.method = &quot;first&quot;) #induce cor through rank-ordering of RN vectors cor(sort.m$P0_m[rm], sort.f$P0_f[rf]) #sort partner ids into dataframe partner.id = data.frame(ID_m = sort.m$ID_m[rm], ID_f = sort.f$ID_f[rf]) partner.id = partner.id[order(partner.id[,&quot;ID_m&quot;]),] #add to list pairs[[j]] = partner.id } partner.id = bind_rows(pairs) partner.id = partner.id[order(partner.id$ID_m),] #put all dyads together partner.id$dyadn = seq(1:nrow(partner.id)) #add values back to dataframe (male and joint) partner.id$P0m &lt;- P$P0[match(partner.id$ID_m,P$ID)] partner.id$P0f &lt;- P$P0[match(partner.id$ID_f,P$ID)] partner.id$P1m &lt;- P$P1[match(partner.id$ID_m,P$ID)] partner.id$P1f &lt;- P$P1[match(partner.id$ID_f,P$ID)] partner.id$A0m &lt;- P$A0[match(partner.id$ID_m,P$ID)] partner.id$A0f &lt;- P$A0[match(partner.id$ID_f,P$ID)] partner.id$A1m &lt;- P$A1[match(partner.id$ID_m,P$ID)] partner.id$A1f &lt;- P$A1[match(partner.id$ID_f,P$ID)] partner.id$E0m &lt;- P$E0[match(partner.id$ID_m,P$ID)] partner.id$E0f &lt;- P$E0[match(partner.id$ID_f,P$ID)] partner.id$E1m &lt;- P$E1[match(partner.id$ID_m,P$ID)] partner.id$E1f &lt;- P$E1[match(partner.id$ID_f,P$ID)] #check correlation again cor(partner.id$P0m, partner.id$P0f) ## [1] 0.3002027 We can now calculate observed aggression measures for a single observation within each dyad. #number of dyads ndyad = nrow(partner.id) pair_df = partner.id #congruent with repeated measures code #correlated residuals between male and females R_cor &lt;- matrix(c(1,r_R,r_R,1), nrow=2, ncol=2) res_sd &lt;- sqrt(res_V) R_cov &lt;- diag(c(res_sd,res_sd)) %*% R_cor %*% diag(c(res_sd,res_sd)) res_ind&lt;-data.frame(rmvnorm(nrow(pair_df), c(0,0), R_cov)) pair_df$resAGm = res_ind$X1 pair_df$resAGf = res_ind$X2 #add interaction number pair_df$turn = rep(1,ndyad) #males #eta_j{t=1} = mu_j + (psi + psi_j)*mu_k pair_df[pair_df$turn==1,&quot;eta_m&quot;] = pair_df[pair_df$turn==1,&quot;P0m&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;P1m&quot;])*(pair_df[pair_df$turn==1,&quot;P0f&quot;]) #females #eta_k{t=1} = mu_k +(psi + psi_k)*mu_j pair_df[pair_df$turn==1,&quot;eta_f&quot;] = pair_df[pair_df$turn==1,&quot;P0f&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;P1f&quot;])*(pair_df[pair_df$turn==1,&quot;P0m&quot;]) #add intercept and residuals (other fixed effects could be added here as well) pair_df$AG_m = alpha_0 + pair_df$eta_m + pair_df$resAGm pair_df$AG_f = alpha_0 + pair_df$eta_f + pair_df$resAGf #create indices for STan Im = I/2 #number of males If = I/2 #number of females N_sex = (I/2)*I_partner #total observations per sex idm&lt;-pair_df$ID_m #male ID idf&lt;-pair_df$ID_f #female ID idf&lt;-idf - Im #within female vector #all partners for each individual #partner IDs for male individuals partners_m&lt;-data.frame(idfocal = rep(1:(I/2)), #all partners ID partner1 = NA, partner2 = NA, partner3 = NA, partner4 = NA) for(i in 1:(I/2)){partners_m[i,c(2:5)] &lt;-partner.id[partner.id$ID_m==i,&quot;ID_f&quot;]} #partner IDs for female individuals partners_f&lt;-data.frame(idfocal = rep((I/2+1):I), #all partners ID partner1 = NA, partner2 = NA, partner3 = NA, partner4 = NA) for(i in (I/2+1):I){partners_f[i-(I/2),c(2:5)] &lt;-partner.id[partner.id$ID_f==i,&quot;ID_m&quot;]} #data prep for Stan stan_data &lt;- list(N_sex = N_sex, I = I, Im=Im, If = If, idm = idm, idf = idf, partners_m = partners_m, partners_f = partners_f, AG_m = pair_df$AG_m, AG_f = pair_df$AG_f, time = pair_df$turn, A = A_mat) It may also be of interest to calculate the true average partner values that well need to center the statistical model. #calculate mean partner phenotype for each subject #average female for male partners mean_0m &lt;- aggregate(P0f ~ ID_m, mean, data = partner.id) names(mean_0m)[2] &lt;- &quot;meanP0m&quot; mean_1m &lt;- aggregate(P1f ~ ID_m, mean, data = partner.id) names(mean_1m)[2] &lt;- &quot;meanP1m&quot; partner.id$meanP0m &lt;- mean_0m$meanP0m[match(partner.id$ID_m,mean_0m$ID_m)] partner.id$meanP1m &lt;- mean_1m$meanP1m[match(partner.id$ID_m,mean_1m$ID_m)] #average male for female partners mean_0f &lt;- aggregate(P0m ~ ID_f, mean, data = partner.id) names(mean_0f)[2] &lt;- &quot;meanP0f&quot; mean_1f &lt;- aggregate(P1m ~ ID_f, mean, data = partner.id) names(mean_1f)[2] &lt;- &quot;meanP1f&quot; partner.id$meanP0f &lt;- mean_0f$meanP0f[match(partner.id$ID_f,mean_0f$ID_f)] partner.id$meanP1f &lt;- mean_1f$meanP1f[match(partner.id$ID_f,mean_1f$ID_f)] For empirical data where the true partner values are unknown, we wont want to average raw partner values subject to measurement error, but instead estimate them directly in our Stan model. 3.2 Estimate the model To code the model, we begin by simplifying the within partner model to remove SRN and residual feedback from the male and female responses, and then we expand it by adding new code for the within-individual centering procedure. write(&quot; data { //indices and scalars used for model specification int&lt;lower=1&gt; N_sex; //total aggression observations per sex (I/2 * 4 lifetime partners) int&lt;lower=0&gt; I; //total individuals (M + F) int&lt;lower=0&gt; Im; //number of males int&lt;lower=0&gt; If; //number of females int&lt;lower=1&gt; idm[N_sex]; //index of male AG observations (of length N_sex) int&lt;lower=1&gt; idf[N_sex]; //index of female AG observations int&lt;lower=1&gt; partners_m [Im,5]; //index of male partner IDs, first column is focal ID (1 + 4 IDs) int&lt;lower=1&gt; partners_f [If,5]; //index of female partner IDs, first column is focal ID (1 + 4 IDs) //empirical data matrix[I,I] A; //relatedness matrix real AG_m[N_sex]; //male aggression measurements real AG_f[N_sex]; //female aggression measurements real time[N_sex]; //time index (=1 for all measures) } transformed data{ matrix[I,I] LA = cholesky_decompose(A); //lower-triangle A matrix } parameters { //population effects real alpha_0; //aggression global intercept real psi_1; //expected interaction coefficient real beta_B; //slope of between-partner component //no way to partition feedback when t=1 //real&lt;lower=-1,upper=1&gt; phi; //(-1,1) ensures unique solution //random effects (standard deviations) vector&lt;lower=0, upper = 1&gt;[2] sd_P; //phenotypic SRN mu &amp; psi SDs vector&lt;lower=0, upper = 1&gt;[2] sd_R; //male &amp; female residual SDs cholesky_factor_corr[2] LG; //genetic SRN correlations cholesky_factor_corr[2] LE; //permanent environmental SRN correlations cholesky_factor_corr[2] LR; //sex-specific residual correlations matrix[I,2] std_devG; //individual-level unscaled G SRN deviations matrix[I,2] std_devE; //individual-level unscaled E SRN deviations //SRN heritability parmameters, i.e. Var(G_RN) / Var(P_RN) //see supplementary appendix SI for further explanation of this parameter vector&lt;lower=0,upper=1&gt;[2] SRN_h2; } transformed parameters { vector&lt;lower=0&gt;[2] sd_G; //SDs of G effects (derived from sd_P) vector&lt;lower=0&gt;[2] sd_E; //SDs of E effects (derived from sd_P) matrix[I,2] SRN_P; //scaled P SRN parameter deviations matrix[I,2] SRN_G; //scaled G SRN parameter deviations matrix[I,2] SRN_E; //scaled E SRN parameter deviations matrix[If, 2] partner_meanm; //average SRN parameters of males&#39; partners matrix[Im, 2] partner_meanf; //average SRN parameters of females&#39; partners //standard deviations of genetic effects //simplified from sqrt ( total RN phenotype variance * h2 ) sd_G[1] = sd_P[1] * sqrt(SRN_h2[1]); //genetic SD for RN intercepts sd_G[2] = sd_P[2] * sqrt(SRN_h2[2]); //genetic SD for RN slopes //standard deviations of environmental effects (total phenotype SD * proportion environment SD) sd_E[1] = sd_P[1] * sqrt(1 - SRN_h2[1]); //environment SD for RN intercepts sd_E[2] = sd_P[2] * sqrt(1 - SRN_h2[2]); //environment SD for RN slopes //matrix normal parameterization of Kronecker product between G and A SRN_G = LA * std_devG * diag_pre_multiply(sd_G, LG)&#39; ; //non-centered parameterization of permanent environmental effects SRN_E = std_devE * diag_pre_multiply(sd_E, LE)&#39;; //phenotypic RN effects (P = G + E); here G = additive genetic effects SRN_P = SRN_G + SRN_E; //calculate the mean SRN parameters of each male&#39;s lifetime partners for(i in 1:Im) partner_meanm[i] = [mean(col(SRN_P[partners_m[i,2:5]],1)), mean(col(SRN_P[partners_m[i,2:5]],2))]; //calculate the mean SRN parameters of each female&#39;s lifetime partners for(i in 1:If) partner_meanf[i] = [mean(col(SRN_P[partners_f[i,2:5]],1)), mean(col(SRN_P[partners_f[i,2:5]],2))]; } model{ //separate male and female vectors for efficiency matrix[Im,2] SRN_Pm = SRN_P[1:Im]; //male SRN phenotypic deviations matrix[If,2] SRN_Pf = SRN_P[(Im+1):I]; //female SRN phenotypic deviations //separate SRN intercepts and slopes (phenotypic deviations) vector[Im] mu_m = col(SRN_Pm,1); //SRN intercepts vector[If] mu_f = col(SRN_Pf,1); vector[Im] psi_m = col(SRN_Pm,2); //SRN slopes vector[If] psi_f = col(SRN_Pf,2); //separate mean partner SRN intercepts and slopes vector[Im] mu_meanm = col(partner_meanm,1); //mean partner SRN intercept for males vector[If] mu_meanf = col(partner_meanf,1); //...for females vector[Im] psi_meanm = col(partner_meanm,2); //mean partner SRN slope for males vector[If] psi_meanf = col(partner_meanf,2); //...for females //add in new vectors for within-individual centering vector[N_sex] eta_Wm; //male SRN trait value vector[N_sex] eta_Wf; //female SRN trait value vector[N_sex] eta_Bm; //individual male SRN trait value toward average partner vector[N_sex] eta_Bf; //individual female SRN trait toward average partner //other components of linear predictor vector[N_sex] linpred_m; //total expected value for male responses vector[N_sex] linpred_f; //total expected value for female responses vector[N_sex] epsilon_m; //residual for male responses vector[N_sex] epsilon_f; //residual for female responses //Male and female aggression response model for (n in 1:N_sex) { //SRN trait values (within-individual centered) //there is no residual feedback, so only t = 1 //within-male male eta[t=1] = mu_j + (psi + psi_j)*(mu_k - mean_mu_K) eta_Wm[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(mu_f[idf[n]] - mu_meanm[idm[n]]) ; //female eta[t=1] = mu_k + (psi + psi_k)*(mu_j - mean_mu_J) eta_Wf[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(mu_m[idm[n]] - mu_meanf[idf[n]]); //average time=1 individual eta (used for feedback process) //between male eta[t=1] = mu_j + psi_j*mean_mu_K eta_Bm[n] = (psi_1 + psi_m[idm[n]])*mu_meanm[idm[n]]; //between female eta[t=1] = mu_k + psi_k*mean_mu_J eta_Bf[n] = (psi_1 + psi_f[idf[n]])*mu_meanf[idf[n]]; //add global intercept and between-individual parameters to linear predictor //other fixed effects can also be added here linpred_m[n] = alpha_0 + eta_Wm[n] + beta_B*eta_Bm[n] ; linpred_f[n] = alpha_0 + eta_Wf[n] + beta_B*eta_Bf[n] ; //there is no residual feedback, so only t = 1 epsilon_m [n] = AG_m[n] - linpred_m[n]; epsilon_f [n] = AG_f[n] - linpred_f[n]; //correlated residuals between partners [epsilon_m[n],epsilon_f[n]]&#39; ~ multi_normal_cholesky([0,0], diag_pre_multiply(sd_R, LR)); } //model priors //fixed effects alpha_0 ~ std_normal(); psi_1 ~ std_normal(); beta_B ~ std_normal(); //random effects to_vector(sd_P) ~ cauchy(0,1); to_vector(sd_R) ~ cauchy(0,1); LG ~ lkj_corr_cholesky(2); LE ~ lkj_corr_cholesky(2); LR ~ lkj_corr_cholesky(2); to_vector(std_devG) ~ std_normal(); to_vector(std_devE) ~ std_normal(); //reaction norm heritability to_vector(SRN_h2) ~ beta(1.2,1.2); } generated quantities{ //cor and cov matrices of SRN parameters and residuals matrix[2,2] Gcor = LG * LG&#39;; //G SRN correlation matric matrix[2,2] Ecor = LE * LE&#39;; //E SRN correlation matric matrix[2,2] Rcor = LR * LR&#39;; //residual correlation matrix matrix[2,2] Rcov = diag_matrix(sd_R)*Rcor*diag_matrix(sd_R); //residual covariance matrix[2,2] Gcov = diag_matrix(sd_G)*Gcor*diag_matrix(sd_G); //G SRN covariance matrix[2,2] Ecov = diag_matrix(sd_E)*Ecor*diag_matrix(sd_E); //E SRN covariance matrix[2,2] Pcov = Gcov + Ecov; //P SRN covariance matrix[2,2] Pcor = inverse(diag_matrix(sd_P))*Pcov*inverse(diag_matrix(sd_P)); //P SRN correlation //variances vector&lt;lower=0&gt;[2] V_P = sd_P .* sd_P; vector&lt;lower=0&gt;[2] V_G = sd_G .* sd_G; vector&lt;lower=0&gt;[2] V_E = sd_E .* sd_E; vector&lt;lower=0&gt;[2] V_R = sd_R .* sd_R; }&quot;, &quot;sam3_2.stan&quot;) As a reminder, this is the structure of the data list necessary for estimating this model. str(stan_data) ## List of 12 ## $ N_sex : num 600 ## $ I : num 300 ## $ Im : num 150 ## $ If : num 150 ## $ idm : int [1:600] 1 1 1 1 2 2 2 2 3 3 ... ## $ idf : num [1:600] 139 113 145 98 8 11 120 129 24 64 ... ## $ partners_m:&#39;data.frame&#39;: 150 obs. of 5 variables: ## ..$ idfocal : int [1:150] 1 2 3 4 5 6 7 8 9 10 ... ## ..$ partner1: int [1:150] 289 158 174 233 300 172 167 250 180 154 ... ## ..$ partner2: int [1:150] 263 161 214 157 202 199 242 255 218 222 ... ## ..$ partner3: int [1:150] 295 270 191 215 227 161 157 169 249 166 ... ## ..$ partner4: int [1:150] 248 279 275 195 155 234 183 241 274 283 ... ## $ partners_f:&#39;data.frame&#39;: 150 obs. of 5 variables: ## ..$ idfocal : int [1:150] 151 152 153 154 155 156 157 158 159 160 ... ## ..$ partner1: int [1:150] 47 27 75 10 5 28 4 2 25 22 ... ## ..$ partner2: int [1:150] 91 57 115 45 79 31 7 52 27 90 ... ## ..$ partner3: int [1:150] 112 86 138 51 81 66 22 98 35 99 ... ## ..$ partner4: int [1:150] 136 148 143 143 116 119 145 127 81 127 ... ## $ AG_m : num [1:600] -0.44192 -0.30244 0.20827 0.00159 1.37946 ... ## $ AG_f : num [1:600] 1.607 0.56 -0.245 0.605 -1.736 ... ## $ time : num [1:600] 1 1 1 1 1 1 1 1 1 1 ... ## $ A : num [1:300, 1:300] 1 0.014 0.0497 0.0156 0.0161 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:300] &quot;ID4737&quot; &quot;ID4876&quot; &quot;ID5016&quot; &quot;ID4625&quot; ... ## .. ..$ : chr [1:300] &quot;ID4737&quot; &quot;ID4876&quot; &quot;ID5016&quot; &quot;ID4625&quot; ... Lets now estimate the model. library(rstan) sam_3.2 = stan_model(&quot;sam3_2.stan&quot;) ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): &#39;C:/rtools40/usr/mingw_/bin/g++&#39; not found stan_results3.2 &lt;- sampling(sam_3.2, data=stan_data, init = 0, warmup=1500, iter = 6000, chains=4, cores=4, control=list(adapt_delta=0.90) ) library(bayesplot) mcmc_areas(stan_results3.2, pars = c( &quot;psi_1&quot;, &quot;beta_B&quot;, &quot;V_P[1]&quot;, &quot;V_P[2]&quot;, &quot;Gcor[2,1]&quot;, &quot;Ecor[2,1]&quot;, &quot;Rcor[2,1]&quot;, &quot;Pcor[2,1]&quot;, &quot;SRN_h2[1]&quot;, &quot;SRN_h2[2]&quot;), prob = 0.9 ) Overall, it seems the model is doing a good job of detecting the population SRN slope (-0.5), albeit with some uncertainty, as well as the range of the phenotypic variance of SRN intercepts and slopes (0.6), the phenotypic correlation between SRN parameters (0.3), and the SRN heritability of intercepts and slopes (0.5). 3.3 Estimating assortment We can also now use the mean partner values calculated in the new model to estimate the assortment coefficients of interest. We expect for this within-individual centered model to do a better job of detecting the known positive assortment between individual and social partners SRN intercepts. #extract posteriors post &lt;- rstan::extract(stan_results3.2) #temporary vectors for assortment coefficients SRN_PV = post$V_P SRN_Psd = post$sd_P SRN_PVmean = post$V_P / I_partner #expected variance for mean of partners SRN_Psdmean = sqrt(SRN_PVmean) #expected SD for mean of partners SRN_focal1 &lt;- post$SRN_P[,,1] #individual intercepts SRN_focal2 &lt;- post$SRN_P[,,2] #individual slopes SRN_partner1 &lt;- cbind(post$partner_meanm[,,1], post$partner_meanf[,,1]) SRN_partner2 &lt;- cbind(post$partner_meanm[,,2], post$partner_meanf[,,2]) #scale mean partner variance to variance of single partner SRN_partner1s = SRN_partner1 for(j in 1:nrow(SRN_partner1)) {SRN_partner1s[j,] = ( SRN_partner1[j,] / SRN_Psdmean[j,1] ) * SRN_Psd[j,1] } SRN_partner2s = SRN_partner2 for(j in 1:nrow(SRN_partner2)) {SRN_partner2s[j,] = ( SRN_partner2[j,] / SRN_Psdmean[j,2] ) * SRN_Psd[j,2] } #assortment matrix Beta_alpha = list() #generate matrices across each posterior sample for(j in 1:nrow(SRN_focal1)) { Beta_mat = matrix(NA,2,2) #mu&#39; ~ mu Beta_mat[1,1] = cov(SRN_focal1[j,], SRN_partner1s[j,])/var(SRN_focal1[j,]) #mu&#39; ~ psi Beta_mat[2,1] = cov(SRN_focal2[j,], SRN_partner1s[j,])/var(SRN_focal2[j,]) #psi&#39; ~ mu Beta_mat[1,2] = cov(SRN_focal1[j,], SRN_partner2s[j,])/var(SRN_focal1[j,]) #psi&#39; ~ psi Beta_mat[2,2] = cov(SRN_focal2[j,], SRN_partner2s[j,])/var(SRN_focal2[j,]) Beta_alpha[[j]] = Beta_mat } #extract beta_mu&#39;mu (assortment on SRN intercepts) Beta_mu = unlist(lapply(Beta_alpha, function(x) x[1,1])) mean(Beta_mu); sum(Beta_mu &gt; 0)/length(Beta_mu) ## [1] 0.2304127 ## [1] 0.9997778 As expected, although the estimated assortment coefficient \\(\\beta_{\\bar{\\mu&#39;}\\mu}\\) is downwardly estimated from its true value 0.3, positive assortment of moderate effect size is detected. 3.4 Phenotypic model A phenotypic between partner model can also be estimated whenever quantitative genetic information is missing. Resources "],["within-and-between-partner-sam.html", "4 Within-and-between partner SAM 4.1 Simulate data 4.2 Estimate the model 4.3 Estimating assortment 4.4 Phenotypic model", " 4 Within-and-between partner SAM As discussed and demonstrated in the previous chapters (2 &amp; 3), within partner variation allows for modelling the temporal dynamics of social interactions, including intrinsic and residual trait feedback, while between partner variation can be used to partition the effects of assortment and social plasticity. Study designs providing both within and between partner measurements will, therefore, tend to be optimally informative about phenotypic interactions and their evolutionary consequences. The formal model for a between-and-within partner SAM combines the basic latent ARMA feedback process of the within partner SAM (Ch 2) with the within-individual centering used to remove bias from the SRN slopes of the between partner SAM (Ch 3). The model for a measurement \\(i\\) of aggression \\(z_{ijt}\\) in focal individual \\(j\\) during a single interaction period \\(t\\) is given by \\[z_{ijt} = \\mu_0 + \\eta_{Wijt} + \\beta_{B}\\eta_{Bijt} + \\xi_{ijt}\\] where \\(\\eta_{Wijt}\\) is the within-individual centered plastic response to the social partner SRN trait value \\[\\eta_{Wijt} = \\begin{Bmatrix} \\mu_j + \\left( \\psi_1 + \\psi_j \\right) \\left( \\mu_k&#39; - \\bar{\\mu}&#39;_K \\right) &amp; \\mathrm{if} \\ t = 1 \\\\ \\mu_j + \\left( \\psi_1 + \\psi_j \\right) \\left( \\eta_{ikt-1}&#39; - \\bar{\\eta}&#39;_{iKt-1} \\right) &amp; \\mathrm{else} \\end{Bmatrix} \\] with \\(\\beta_{B}\\eta_{Bijt}\\) reflecting the association with the average partner SRN trait value \\[\\eta_{Bijt} = \\begin{Bmatrix} \\left( \\psi_1 + \\psi_j \\right) \\bar{\\mu}&#39;_K &amp; \\mathrm{if} \\ t = 1 \\\\ \\left( \\psi_1 + \\psi_j \\right) \\bar{\\eta}&#39;_{iKt-1} &amp; \\mathrm{else} \\end{Bmatrix} \\] scaled by the between partner regression coefficient \\(\\beta_{B}\\). In addition, \\(\\xi_{ijt}\\) captures SRN measurement error caused by residual feedback over time \\[\\xi_{ijt} = \\begin{Bmatrix} \\epsilon_{ijt} &amp; \\mathrm{if} \\ t = 1 \\\\ \\epsilon_{ijt} + \\phi\\epsilon_{ikt-1}&#39; &amp; \\mathrm{else} \\end{Bmatrix} \\] Similarly, for the social partner \\[z_{ikt}&#39; = \\mu_0 + \\eta_{Wikt}&#39; + \\beta_B\\eta_{Bikt}&#39; + \\xi_{ikt}&#39;\\] \\[\\eta_{Wikt}&#39; = \\begin{Bmatrix} \\mu_k&#39; + \\left( \\psi_1 + \\psi_k&#39; \\right)\\left( \\mu_j - \\bar{\\mu}_J \\right) &amp; \\mathrm{if} \\ t = 1 \\\\ \\mu_k&#39; + \\left( \\psi_1 + \\psi_k&#39; \\right)\\left( \\eta_{ijt} - \\bar{\\eta}_{iJt} \\right) &amp; \\mathrm{else} \\end{Bmatrix} \\] \\[\\eta_{Bikt}&#39; = \\begin{Bmatrix} \\left( \\psi_1 + \\psi_k&#39; \\right) \\bar{\\mu}_J &amp; \\mathrm{if} \\ t = 1 \\\\ \\left( \\psi_1 + \\psi_k&#39; \\right) \\bar{\\eta}_{iJt} &amp; \\mathrm{else} \\end{Bmatrix} \\] \\[\\xi_{ikt}&#39; = \\begin{Bmatrix} \\epsilon_{ikt}&#39; &amp; \\mathrm{if} \\ t = 1 \\\\ \\epsilon_{ikt}&#39; + \\phi\\epsilon_{ijt-1} &amp; \\mathrm{else} \\end{Bmatrix} \\] The random effects are assumed to be well-described by multivariate normal distributions. \\[\\mu_j = \\mu_{\\mathrm{A}j} + \\mu_{\\mathrm{E}j}, \\quad \\psi_j = \\psi_{\\mathrm{A}j} + \\psi_{\\mathrm{E}j}\\] \\[\\mu_k&#39; = \\mu_{\\mathrm{A}k}&#39; + \\mu_{\\mathrm{E}j}&#39;, \\quad \\psi_k&#39; = \\psi_{\\mathrm{A}k}&#39; + \\psi_{\\mathrm{E}k}&#39;\\] \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{A}}}, \\boldsymbol{\\mu&#39;_{\\mathrm{A}}},\\boldsymbol{\\psi_{\\mathrm{A}}},\\boldsymbol{\\psi}&#39;_{\\mathrm{A}} \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{G}} \\otimes \\boldsymbol{\\mathrm{A}} ) \\] \\[\\begin{bmatrix} \\boldsymbol{\\mu_{\\mathrm{E}}}, \\boldsymbol{\\mu&#39;_{\\mathrm{E}}},\\boldsymbol{\\psi_{\\mathrm{E}}},\\boldsymbol{\\psi}&#39;_{\\mathrm{E}} \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{E}} \\otimes \\boldsymbol{\\mathrm{I}} ) \\] \\[\\begin{bmatrix} \\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon}&#39; \\end{bmatrix}^{\\mathrm{T}} \\sim \\mathrm{MVNormal}(\\boldsymbol{0}, \\boldsymbol{\\mathrm{\\Sigma}} ) \\] We also assume that the social reaction norm (SRN) intercept and slope (co)variances are equivalent for focal (\\(\\boldsymbol{\\mu},\\boldsymbol{\\psi}\\)) and social partners (\\(\\boldsymbol{\\mu}&#39;,\\boldsymbol{\\psi}&#39;\\)). The \\(\\boldsymbol{G}\\) matrix can therefore be reduced to a 2x2 matrix for all individuals in the population \\[\\boldsymbol{\\mathrm{G}}= \\begin{bmatrix} \\mathrm{var([\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;])} &amp; \\mathrm{cov([\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;],[\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;])} \\\\ \\mathrm{cov([\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;],[\\boldsymbol{\\mu},\\boldsymbol{\\mu}&#39;])} &amp; \\mathrm{var([\\boldsymbol{\\psi},\\boldsymbol{\\psi}&#39;])} \\end{bmatrix}\\] The residual matrix \\(\\boldsymbol{\\Sigma}\\) estimates the association among focal and social partners residuals. \\[\\boldsymbol{\\Sigma}= \\begin{bmatrix} \\mathrm{var(\\boldsymbol{\\epsilon})} &amp; \\mathrm{cov}(\\boldsymbol{\\epsilon},\\boldsymbol{\\epsilon}&#39;) \\\\ \\mathrm{cov}(\\boldsymbol{\\epsilon}&#39;,\\boldsymbol{\\epsilon}) &amp; \\mathrm{var(\\boldsymbol{\\epsilon&#39;})} \\end{bmatrix}\\] This model is, therefore, appropriate for situations where the distinction between focal and partner is semi-arbitrary, e.g. when measuring within-sex interactions or when males and females exhibit similar patterns of phenotypic variation. In this case, we make the latter assumption for simplicity. To account for differences between the responses of focal individuals and social partners, the model can simply be extended with additional parameters, e.g. specifying separate \\(G_M\\) and \\(G_F\\) matrices for males and female respective genetic (co)variances and so on. 4.1 Simulate data We can simulate data from this model using the custom pedfun() function introduced in Ch. 1.5, as well by integrating the basic simulation approach outlined in the previous SAM chapters for repeated interactions with partners (Ch. 2) as well as across partners (Ch. 3). We assume that interactions occur with 4 lifetime partners with two measurements per individual within each dyad. This empirical information allows us to more effectively partition within and between dyad variation. library(mvtnorm) #common settings I_partner = 4 #partners/individual I_obs = 2 #observations/individual/seasonal partner I_sample = I_partner*I_obs #samples/individual #population properties I=300 #total individuals for simulation popmin=400 popmax=600 ngenerations = 10 nids&lt;-sample(popmin:popmax, ngenerations, replace=TRUE) #N / generation epm = sample(seq(0.15, 0.25,by=0.05),1) #extra-pair mating nonb = sample(seq(0.4,0.6,by=0.05),1) #proportion of non-breeding / generation #relatedness matrix A_mat &lt;- pedfun(popmin=popmin, popmax=popmax, ngenerations=ngenerations, epm=epm, nonb=nonb, nids=nids, I=I, missing=FALSE) ##################################################################### #Parameter values ##################################################################### alpha_0 = 0 #global intercept psi_1 = -0.5 #population interaction coefficient phi = 0.5 #residual feedback coefficient (epsilon_j ~ epsilon_t-1k) SD_intercept = 0.3 #standard deviation of SRN intercepts SD_slope = 0.3 #SD of SRN slopes r_alpha = 0.3 #assortment coefficient (expressed as correlation) r_G = 0.3 #genetic correlation of random intercepts and slopes r_E = 0.3 #environmental correlation r_R = -0.3 #residual effect correlation (epsilon_tj = epsilon_tk) V_G = 0.3 #genetic variance of REs V_E = 0.3 #genetic variance of REs res_V = 1 #Random effect correlations G_cor &lt;- matrix(c(1,r_G,r_G,1), nrow=2, ncol=2) #mu_A, beta_A G_sd &lt;- c(sqrt(V_G),sqrt(V_G)) #G effect sds G_cov &lt;- diag(G_sd) %*% G_cor %*% diag(G_sd) E_cor &lt;- matrix(c(1,r_E,r_E,1), nrow=2, ncol=2) #mu_E, beta_E E_sd &lt;- c(sqrt(V_E),sqrt(V_E)) #E effect sds E_cov &lt;- diag(E_sd) %*% E_cor %*% diag(E_sd) #matrices G_block &lt;- G_cov %x% A_mat E_block &lt;- E_cov %x% diag(1,I) #generate correlated REs Gvalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=G_block) G_val = data.frame(matrix(Gvalues, nrow=I, ncol=2)) cor(G_val) ## X1 X2 ## X1 1.0000000 0.2647347 ## X2 0.2647347 1.0000000 Evalues &lt;- rmvnorm(1, mean=rep(0,I*2), sigma=E_block) E_val = data.frame(matrix(Evalues, nrow=I, ncol=2)) cor(E_val) ## X1 X2 ## X1 1.0000000 0.2820765 ## X2 0.2820765 1.0000000 #combine temporary object for all SRN parameters #use shorthand mu = 0, psi = 1 P = cbind(G_val,E_val) colnames(P) = c(&quot;A0&quot;, &quot;A1&quot;, &quot;E0&quot;, &quot;E1&quot;) #individual phenotypic REs #use shorthand mu = 0, psi = 1 P$P0 = P$A0 + P$E0 P$P1 = P$A1 + P$E1 #add ID P$ID = seq(1:I) library(dplyr) library(MASS) pairs = list() for (j in 1:I_partner){ #male RN intercept (x I_partner for multiple lifetime partners) sort.m &lt;- data.frame(P0_m = P$P0[1:(I/2)], ID_m = (1:(I/2)) ) sort.m&lt;-sort.m[order(sort.m[,&quot;P0_m&quot;]),] #female phenotypic RN slopes sort.f &lt;- data.frame(P0_f = P$P0[(I/2 + 1):I], ID_f = ((I/2+1):I) ) sort.f&lt;-sort.f[order(sort.f[,&quot;P0_f&quot;]),] #generate random dataset with desired rank-order correlation temp_mat &lt;- matrix(r_alpha, ncol = 2, nrow = 2) #cor of male and female values diag(temp_mat) &lt;- 1 #cor matrix #sim values temp_data1&lt;- mvrnorm(n = I/2, mu = c(0, 0), Sigma = temp_mat, empirical=TRUE) #ranks of random data rm &lt;- rank(temp_data1[ , 1], ties.method = &quot;first&quot;) rf &lt;- rank(temp_data1[ , 2], ties.method = &quot;first&quot;) #induce cor through rank-ordering of RN vectors cor(sort.m$P0_m[rm], sort.f$P0_f[rf]) #sort partner ids into dataframe partner.id = data.frame(ID_m = sort.m$ID_m[rm], ID_f = sort.f$ID_f[rf]) partner.id = partner.id[order(partner.id[,&quot;ID_m&quot;]),] #add to list pairs[[j]] = partner.id } partner.id = bind_rows(pairs) partner.id = partner.id[order(partner.id$ID_m),] #put all dyads together partner.id$dyadn = seq(1:nrow(partner.id)) #add values back to dataframe (male and joint) partner.id$P0m &lt;- P$P0[match(partner.id$ID_m,P$ID)] partner.id$P0f &lt;- P$P0[match(partner.id$ID_f,P$ID)] partner.id$P1m &lt;- P$P1[match(partner.id$ID_m,P$ID)] partner.id$P1f &lt;- P$P1[match(partner.id$ID_f,P$ID)] partner.id$A0m &lt;- P$A0[match(partner.id$ID_m,P$ID)] partner.id$A0f &lt;- P$A0[match(partner.id$ID_f,P$ID)] partner.id$A1m &lt;- P$A1[match(partner.id$ID_m,P$ID)] partner.id$A1f &lt;- P$A1[match(partner.id$ID_f,P$ID)] partner.id$E0m &lt;- P$E0[match(partner.id$ID_m,P$ID)] partner.id$E0f &lt;- P$E0[match(partner.id$ID_f,P$ID)] partner.id$E1m &lt;- P$E1[match(partner.id$ID_m,P$ID)] partner.id$E1f &lt;- P$E1[match(partner.id$ID_f,P$ID)] #check correlation again cor(partner.id$P0m, partner.id$P0f) ## [1] 0.2888771 Now we want to expand the data frame for multiple measurements within each dyad. #calculate mean partner phenotype for each subject #average female for male partners mean_0m &lt;- aggregate(P0f ~ ID_m, mean, data = partner.id) names(mean_0m)[2] &lt;- &quot;meanP0m&quot; mean_1m &lt;- aggregate(P1f ~ ID_m, mean, data = partner.id) names(mean_1m)[2] &lt;- &quot;meanP1m&quot; partner.id$meanP0m &lt;- mean_0m$meanP0m[match(partner.id$ID_m,mean_0m$ID_m)] partner.id$meanP1m &lt;- mean_1m$meanP1m[match(partner.id$ID_m,mean_1m$ID_m)] #average male for female partners mean_0f &lt;- aggregate(P0m ~ ID_f, mean, data = partner.id) names(mean_0f)[2] &lt;- &quot;meanP0f&quot; mean_1f &lt;- aggregate(P1m ~ ID_f, mean, data = partner.id) names(mean_1f)[2] &lt;- &quot;meanP1f&quot; partner.id$meanP0f &lt;- mean_0f$meanP0f[match(partner.id$ID_f,mean_0f$ID_f)] partner.id$meanP1f &lt;- mean_1f$meanP1f[match(partner.id$ID_f,mean_1f$ID_f)] #number of dyads ndyad = nrow(partner.id) #expand for repeated measures partner.id$rep &lt;- I_obs pair_df &lt;- partner.id[rep(row.names(partner.id), partner.id$rep),] #correlations cor(partner.id$P0m, partner.id$P0f) ## [1] 0.2888771 cor(partner.id$P1m, partner.id$P0f) ## [1] 0.09417638 cor(partner.id$P0m, partner.id$P1f) ## [1] 0.1394709 cor(partner.id$P1m, partner.id$P1f) ## [1] 0.06740782 The responses can now be sampled. Rather than directly within-individual centering responses and specifying the between-partner regression coefficient \\(\\beta_{B}\\) in the simulation, we assume partners respond to the total SRN trait value of their partner. Therefore, we expect \\(\\beta_{B}=1\\). ##################################################################### #Additional effects ##################################################################### #correlated residuals between male and females R_cor &lt;- matrix(c(1,r_R,r_R,1), nrow=2, ncol=2) res_sd &lt;- sqrt(res_V) R_cov &lt;- diag(c(res_sd,res_sd)) %*% R_cor %*% diag(c(res_sd,res_sd)) res_ind&lt;-data.frame(rmvnorm(nrow(pair_df), c(0,0), R_cov)) pair_df$resAGm = res_ind$X1 pair_df$resAGf = res_ind$X2 ##################################################################### #Simulate responses over t = {1,2} per partner ##################################################################### #add interaction number pair_df$turn = rep(c(1,2),ndyad) #average male social environment at time = 1 pair_df[pair_df$turn==1,&quot;meaneta_m&quot;] = pair_df[pair_df$turn==1,&quot;meanP0m&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;meanP1m&quot;])*(pair_df[pair_df$turn==1,&quot;P0m&quot;]) #average female social environment at time = 1 pair_df[pair_df$turn==1,&quot;meaneta_f&quot;] = pair_df[pair_df$turn==1,&quot;meanP0f&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;meanP1f&quot;])*(pair_df[pair_df$turn==1,&quot;P0f&quot;]) #individual prediction at t = 1 #males #eta_j{t=1} = mu_j + psi_j*(mu_k - mu_meanK) pair_df[pair_df$turn==1,&quot;eta_m&quot;] = pair_df[pair_df$turn==1,&quot;P0m&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;P1m&quot;])*(pair_df[pair_df$turn==1,&quot;P0f&quot;]) #females #eta_k{t=1} = mu_k + psi_k*(mu_j - mu_meanJ) pair_df[pair_df$turn==1,&quot;eta_f&quot;] = pair_df[pair_df$turn==1,&quot;P0f&quot;] + (psi_1 + pair_df[pair_df$turn==1,&quot;P1f&quot;])*(pair_df[pair_df$turn==1,&quot;P0m&quot;]) #individual prediction at t = 2 #eta_j{t=2} = mu_j + psi_j*(eta_k{t=1} - eta_meanK{t=1}) pair_df[pair_df$turn==2,&quot;eta_m&quot;] = pair_df[pair_df$turn==2,&quot;P0m&quot;] + (psi_1 + pair_df[pair_df$turn==2,&quot;P1m&quot;])*(pair_df[pair_df$turn==1,&quot;eta_f&quot;]) #females pair_df[pair_df$turn==2,&quot;eta_f&quot;] = pair_df[pair_df$turn==2,&quot;P0f&quot;] + (psi_1 + pair_df[pair_df$turn==2,&quot;P1f&quot;])*(pair_df[pair_df$turn==1,&quot;eta_m&quot;]) #add intercept and residual pair_df$AG_m = alpha_0 + pair_df$eta_m + pair_df$resAGm pair_df$AG_f = alpha_0 + pair_df$eta_f + pair_df$resAGf #add residual feedback pair_df[pair_df$turn==2,&quot;AG_m&quot;] = pair_df[pair_df$turn==2,&quot;AG_m&quot;] + phi * pair_df[pair_df$turn==1,&quot;resAGf&quot;] pair_df[pair_df$turn==2,&quot;AG_f&quot;] = pair_df[pair_df$turn==2,&quot;AG_f&quot;] + phi * pair_df[pair_df$turn==1,&quot;resAGm&quot;] This data frame along with indices of male and female IDs are then combined in a list for Stan. ##################################################################### #Prepare data for Stan ##################################################################### #individual indices Im = I/2 #number of males If = I/2 #number of females N_sex = (I/2)*2*4 #total observations per sex idm&lt;-pair_df$ID_m #male ID idf&lt;-pair_df$ID_f #female ID idf&lt;-idf - (Im) #index within female vector #partner IDs for male individuals partners_m&lt;-data.frame(idfocal = rep(1:(I/2)), #all partners ID partner1 = NA, partner2 = NA, partner3 = NA, partner4 = NA) for(i in 1:(I/2)){partners_m[i,c(2:5)] &lt;-partner.id[partner.id$ID_m==i,&quot;ID_f&quot;]} #partner IDs for female individuals partners_f&lt;-data.frame(idfocal = rep((I/2+1):I), #all partners ID partner1 = NA, partner2 = NA, partner3 = NA, partner4 = NA) for(i in (I/2+1):I){partners_f[i-(I/2),c(2:5)] &lt;-partner.id[partner.id$ID_f==i,&quot;ID_m&quot;]} ###################### #data prep for Stan stan_data &lt;- list(N_sex = N_sex, I = I, Im=Im, If = If, idm = idm, idf = idf, partners_m = partners_m, partners_f = partners_f, AG_m = pair_df$AG_m, AG_f = pair_df$AG_f, time = pair_df$turn, A = A_mat) 4.2 Estimate the model The within and between partner model code extends the within individual centered, between partner model to account for longitudinal feedback effects within dyads. These changes are accomplished in the parameters as well as the model program blocks. In the latter, a conditional statement is added to account for the effects on \\(\\eta_{ijt}\\) and \\(\\eta&#39;_{ikt}\\) at \\(t=1\\) and \\(t&gt;1\\), and similarly for the residual feedback effects \\(\\xi_j\\) and \\(\\xi&#39;_k\\). write(&quot; data { //indices and scalars used for model specification int&lt;lower=1&gt; N_sex; //total aggression observations per sex (I/2 * 4 lifetime partners) int&lt;lower=0&gt; I; //total individuals (M + F) int&lt;lower=0&gt; Im; //number of males int&lt;lower=0&gt; If; //number of females int&lt;lower=1&gt; idm[N_sex]; //index of male AG observations (of length N_sex) int&lt;lower=1&gt; idf[N_sex]; //index of female AG observations int&lt;lower=1&gt; partners_m [Im,5]; //index of male partner IDs, first column is focal ID (1 + 4 IDs) int&lt;lower=1&gt; partners_f [If,5]; //index of female partner IDs, first column is focal ID (1 + 4 IDs) //empirical data matrix[I,I] A; //relatedness matrix real AG_m[N_sex]; //male aggression measurements real AG_f[N_sex]; //female aggression measurements real time[N_sex]; //time index (=1 for all measures) } transformed data{ matrix[I,I] LA = cholesky_decompose(A); //lower-triangle A matrix } parameters { //population effects real alpha_0; //aggression global intercept real psi_1; //expected interaction coefficient real beta_B; //between partner effect real&lt;lower=-1,upper=1&gt; phi; //(-1,1) ensures unique solution //no way to partition feedback when t=1 //real&lt;lower=-1,upper=1&gt; phi; //(-1,1) ensures unique solution //random effects (standard deviations) vector&lt;lower=0, upper = 1&gt;[2] sd_P; //phenotypic SRN mu &amp; psi SDs vector&lt;lower=0, upper = 1&gt;[2] sd_R; //male &amp; female residual SDs cholesky_factor_corr[2] LG; //genetic SRN correlations cholesky_factor_corr[2] LE; //permanent environmental SRN correlations cholesky_factor_corr[2] LR; //sex-specific residual correlations matrix[I,2] std_devG; //individual-level unscaled G SRN deviations matrix[I,2] std_devE; //individual-level unscaled E SRN deviations //SRN heritability parmameters, i.e. Var(G_RN) / Var(P_RN) //see supplementary appendix SI for further explanation of this parameter vector&lt;lower=0,upper=1&gt;[2] SRN_h2; } transformed parameters { vector&lt;lower=0&gt;[2] sd_G; //SDs of G effects (derived from sd_P) vector&lt;lower=0&gt;[2] sd_E; //SDs of E effects (derived from sd_P) matrix[I,2] SRN_P; //scaled P SRN parameter deviations matrix[I,2] SRN_G; //scaled G SRN parameter deviations matrix[I,2] SRN_E; //scaled E SRN parameter deviations matrix[If, 2] partner_meanm; //average SRN parameters of males&#39; partners matrix[Im, 2] partner_meanf; //average SRN parameters of females&#39; partners //standard deviations of genetic effects //simplified from sqrt ( total RN phenotype variance * h2 ) sd_G[1] = sd_P[1] * sqrt(SRN_h2[1]); //genetic SD for RN intercepts sd_G[2] = sd_P[2] * sqrt(SRN_h2[2]); //genetic SD for RN slopes //standard deviations of environmental effects (total phenotype SD * proportion environment SD) sd_E[1] = sd_P[1] * sqrt(1 - SRN_h2[1]); //environment SD for RN intercepts sd_E[2] = sd_P[2] * sqrt(1 - SRN_h2[2]); //environment SD for RN slopes //matrix normal parameterization of Kronecker product between G and A SRN_G = LA * std_devG * diag_pre_multiply(sd_G, LG)&#39; ; //non-centered parameterization of permanent environmental effects SRN_E = std_devE * diag_pre_multiply(sd_E, LE)&#39;; //phenotypic RN effects (P = G + E); here G = additive genetic effects SRN_P = SRN_G + SRN_E; //calculate the mean SRN parameters of each male&#39;s lifetime partners for(i in 1:Im) partner_meanm[i] = [mean(col(SRN_P[partners_m[i,2:5]],1)), mean(col(SRN_P[partners_m[i,2:5]],2))]; //calculate the mean SRN parameters of each female&#39;s lifetime partners for(i in 1:If) partner_meanf[i] = [mean(col(SRN_P[partners_f[i,2:5]],1)), mean(col(SRN_P[partners_f[i,2:5]],2))]; } model{ //separate male and female vectors for efficiency matrix[Im,2] SRN_Pm = SRN_P[1:Im]; //male SRN phenotypic deviations matrix[If,2] SRN_Pf = SRN_P[(Im+1):I]; //female SRN phenotypic deviations //separate SRN intercepts and slopes (phenotypic deviations) vector[Im] mu_m = col(SRN_Pm,1); //SRN intercepts vector[If] mu_f = col(SRN_Pf,1); vector[Im] psi_m = col(SRN_Pm,2); //SRN slopes vector[If] psi_f = col(SRN_Pf,2); //separate mean partner SRN intercepts and slopes (deviations) vector[Im] mu_meanm = col(partner_meanm,1); //mean partner SRN intercept for males vector[If] mu_meanf = col(partner_meanf,1); //...for females vector[Im] psi_meanm = col(partner_meanm,2); //mean partner SRN slope for males vector[If] psi_meanf = col(partner_meanf,2); //...for females //initialize vectors for constructing individual-centered linear predictors vector[N_sex] eta_Wm; //within-individual centered male SRN trait value vector[N_sex] eta_Wf; //within-individual centered female SRN trait value vector[N_sex] eta_Bm; //individual male SRN trait value toward average partner vector[N_sex] eta_Bf; //individual female SRN trait toward average partner vector[N_sex] eta_meanm; //average SRN partner values for males vector[N_sex] eta_meanf; //average SRN partner values for females vector[N_sex] linpred_m; //expected value for male responses vector[N_sex] linpred_f; //expected value for female responses vector[N_sex] epsilon_m; //residuals for male responses vector[N_sex] epsilon_f; //residuals for male responses //Male and female aggression response model for (n in 1:N_sex) { //SRN trait values //assumes that n = 1 in the context of an ongoing social interaction //if n = 1 prior to social context, then specify eta[t=1] = mu_j instead if (time[n]==1) { //within-individual centered eta //male eta[t=1] = mu_j + psi_j*(mu_k - mu_meanK) eta_Wm[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(mu_f[idf[n]] - mu_meanm[idm[n]]) ; //female eta[t=1] = mu_k + psi_k*(mu_j - mu_meanJ) eta_Wf[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(mu_m[idm[n]] - mu_meanf[idf[n]]); //average individual eta //male eta[t=1] = mu_j + psi_j*mu_k eta_Bm[n] = (psi_1 + psi_m[idm[n]])*mu_meanm[idm[n]]; //female eta[t=1] = mu_k + psi_k*mu_j eta_Bf[n] = (psi_1 + psi_f[idf[n]])*mu_meanf[idf[n]]; //average partner eta[t=1] //average eta males&#39; partners [t=1] = mu_meanK + psi_meanK*mu_j eta_meanm[n] = mu_meanm[idm[n]] + (psi_1 + psi_meanm[idm[n]])*mu_m[idm[n]]; //average eta females&#39; partners [t=1] = mu_meanJ + psi_meanJ*mu_k eta_meanf[n] = mu_meanf[idf[n]] + (psi_1 + psi_meanf[idf[n]])*mu_f[idf[n]]; } else { //within-individual centered eta //male eta[t=2] = mu_j + psi_j*(eta_k[t=1] - eta_meanK[t=1]) eta_Wm[n] = mu_m[idm[n]] + (psi_1 + psi_m[idm[n]])*(eta_Wf[n-1] - eta_meanm[n-1]); //female eta[t=2] = mu_k + psi_k*(eta_j[t=1] - eta_meanJ[t=1]) eta_Wf[n] = mu_f[idf[n]] + (psi_1 + psi_f[idf[n]])*(eta_Wm[n-1] - eta_meanf[n-1]); //average individual eta //male average eta[t=2] = mu_j + psi_j*eta_meanK[t=1] eta_Bm[n] = (psi_1 + psi_m[idm[n]])*eta_meanm[n-1]; //female average eta[t=2] = mu_k + psi_k*eta_meanJ[t=1] eta_Bf[n] = (psi_1 + psi_f[idf[n]])*eta_meanf[n-1]; //average eta males&#39; partners [t=1] = mu_meanK + psi_meanK*mean eta_j[t-1] eta_meanm[n] = mu_meanm[idm[n]] + (psi_1 + psi_meanm[idm[n]])*(mu_m[idm[n]] + eta_Bm[n-1]); //female average partner eta eta_meanf[n] = mu_meanf[idf[n]] + (psi_1 + psi_meanf[idf[n]])*(mu_f[idf[n]] + eta_Bf[n-1]); } //add global intercept and between-individual parameters to linear predictor //other fixed effects can also be added here linpred_m[n] = alpha_0 + eta_Wm[n] + beta_B*eta_Bm[n]; //+beta_B*eta_Bm[n] linpred_f[n] = alpha_0 + eta_Wf[n] + beta_B*eta_Bf[n]; //+beta_B*eta_Bf[n] //residual trait values if(time[n]==1) { epsilon_m [n] = AG_m[n] - linpred_m[n]; epsilon_f [n] = AG_f[n] - linpred_f[n]; } else { linpred_m[n] = linpred_m[n] + phi * epsilon_f[n-1]; epsilon_m[n] = AG_m[n] - linpred_m[n]; linpred_f[n] = linpred_f[n] + phi * epsilon_m[n-1]; epsilon_f[n] = AG_f[n] - linpred_f[n]; } //correlated residuals between partners [epsilon_m[n],epsilon_f[n]]&#39; ~ multi_normal_cholesky([0,0], diag_pre_multiply(sd_R, LR)); } //model priors //fixed effects alpha_0 ~ std_normal(); psi_1 ~ std_normal(); beta_B ~ std_normal(); phi ~ std_normal(); //random effects to_vector(sd_P) ~ cauchy(0,1); to_vector(sd_R) ~ cauchy(0,1); LG ~ lkj_corr_cholesky(2); LE ~ lkj_corr_cholesky(2); LR ~ lkj_corr_cholesky(2); to_vector(std_devG) ~ std_normal(); to_vector(std_devE) ~ std_normal(); //reaction norm heritability to_vector(SRN_h2) ~ beta(1.2,1.2); } generated quantities{ //cor and cov matrices of SRN parameters and residuals matrix[2,2] Gcor = LG * LG&#39;; //G SRN correlation matric matrix[2,2] Ecor = LE * LE&#39;; //E SRN correlation matric matrix[2,2] Rcor = LR * LR&#39;; //residual correlation matrix matrix[2,2] Rcov = diag_matrix(sd_R)*Rcor*diag_matrix(sd_R); //residual covariance matrix[2,2] Gcov = diag_matrix(sd_G)*Gcor*diag_matrix(sd_G); //G SRN covariance matrix[2,2] Ecov = diag_matrix(sd_E)*Ecor*diag_matrix(sd_E); //E SRN covariance matrix[2,2] Pcov = Gcov + Ecov; //P SRN covariance matrix[2,2] Pcor = inverse(diag_matrix(sd_P))*Pcov*inverse(diag_matrix(sd_P)); //P SRN correlation //variances vector&lt;lower=0&gt;[2] V_P = sd_P .* sd_P; vector&lt;lower=0&gt;[2] V_G = sd_G .* sd_G; vector&lt;lower=0&gt;[2] V_E = sd_E .* sd_E; vector&lt;lower=0&gt;[2] V_R = sd_R .* sd_R; }&quot;, &quot;sam3_3w.stan&quot;) Depending on the sample size set during the simulation, this model will likely take 30+ min to finish sampling. The total number of iterations can be reduced to save time, but is set to a large value here to ensure sufficient effective sample sizes for some parameters. library(rstan) sam_3.3 = stan_model(&quot;sam3_3w.stan&quot;) stan_results3.3 &lt;- sampling(sam_3.3, data=stan_data, init = 0, warmup=1500, iter = 6000, chains=4, cores=4, control=list(adapt_delta=0.90) ) library(bayesplot) mcmc_areas(stan_results3.3, pars = c( &quot;psi_1&quot;, &quot;beta_B&quot;, &quot;V_P[1]&quot;, &quot;V_P[2]&quot;, &quot;Gcor[2,1]&quot;, &quot;Ecor[2,1]&quot;, &quot;Rcor[2,1]&quot;, &quot;Pcor[2,1]&quot;, &quot;SRN_h2[1]&quot;, &quot;SRN_h2[2]&quot;), prob = 0.9 ) The model seems to be doing well overall, detecting the negative population SRN slope (-0.5) as well as approximating the locaiton of the total phenotypic variance of SRN intercepts and slopes (0.6), the phenotypic correlation between SRN parameters (0.3), the SRN heritability of intercepts and slopes (0.5), and the expected between partner regresson coefficient (1). 4.3 Estimating assortment The mean partner intrinsic trait values calculated in the model can now be used to estimate the assortment coefficients of interest. #extract posteriors post &lt;- rstan::extract(stan_results3.3) #temporary vectors for assortment coefficients SRN_PV = post$V_P SRN_Psd = post$sd_P SRN_PVmean = post$V_P / I_partner #expected variance for mean of partners SRN_Psdmean = sqrt(SRN_PVmean) #expected SD for mean of partners SRN_focal1 &lt;- post$SRN_P[,,1] #individual intercepts SRN_focal2 &lt;- post$SRN_P[,,2] #individual slopes SRN_partner1 &lt;- cbind(post$partner_meanm[,,1], post$partner_meanf[,,1]) SRN_partner2 &lt;- cbind(post$partner_meanm[,,2], post$partner_meanf[,,2]) #scale mean partner variance to variance of single partner SRN_partner1s = SRN_partner1 for(j in 1:nrow(SRN_partner1)) {SRN_partner1s[j,] = ( SRN_partner1[j,] / SRN_Psdmean[j,1] ) * SRN_Psd[j,1] } SRN_partner2s = SRN_partner2 for(j in 1:nrow(SRN_partner2)) {SRN_partner2s[j,] = ( SRN_partner2[j,] / SRN_Psdmean[j,2] ) * SRN_Psd[j,2] } #assortment matrix Beta_alpha = list() #generate matrices across each posterior sample for(j in 1:nrow(SRN_focal1)) { Beta_mat = matrix(NA,2,2) #mu&#39; ~ mu Beta_mat[1,1] = cov(SRN_focal1[j,], SRN_partner1s[j,])/var(SRN_focal1[j,]) #mu&#39; ~ psi Beta_mat[2,1] = cov(SRN_focal2[j,], SRN_partner1s[j,])/var(SRN_focal2[j,]) #psi&#39; ~ mu Beta_mat[1,2] = cov(SRN_focal1[j,], SRN_partner2s[j,])/var(SRN_focal1[j,]) #psi&#39; ~ psi Beta_mat[2,2] = cov(SRN_focal2[j,], SRN_partner2s[j,])/var(SRN_focal2[j,]) Beta_alpha[[j]] = Beta_mat } #extract beta_mu&#39;mu (assortment on SRN intercepts) Beta_mu = unlist(lapply(Beta_alpha, function(x) x[1,1])) mean(Beta_mu); sum(Beta_mu &gt; 0)/length(Beta_mu) ## [1] 0.3985158 ## [1] 1 Positive assortment of moderate effect size is detected. 4.4 Phenotypic model A phenotypic within and between partner model can also be estimated whenever quantitative genetic information is missing. "],["extending-sams.html", "5 Extending SAMs", " 5 Extending SAMs body { text-align: justify} This section is a work in progress. "],["resources.html", "Resources", " Resources "]]
